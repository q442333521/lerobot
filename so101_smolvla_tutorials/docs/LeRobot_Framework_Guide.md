# LeRobot æ¡†æ¶æ·±å…¥è§£æ

> **å¿«é€ŸæŒæ¡ LeRobotï¼šæ¨¡å—åŒ–æœºå™¨äººå­¦ä¹ æ¡†æ¶**

---

## ğŸ“‹ ç›®å½•

1. [æ¡†æ¶æ¦‚è¿°](#æ¡†æ¶æ¦‚è¿°)
2. [æ ¸å¿ƒæ¶æ„](#æ ¸å¿ƒæ¶æ„)
3. [å…³é”®æ¨¡å—è¯¦è§£](#å…³é”®æ¨¡å—è¯¦è§£)
4. [æ•°æ®æµç¨‹](#æ•°æ®æµç¨‹)
5. [æ”¯æŒçš„ç­–ç•¥](#æ”¯æŒçš„ç­–ç•¥)
6. [ä¼˜ç¼ºç‚¹åˆ†æ](#ä¼˜ç¼ºç‚¹åˆ†æ)
7. [å®ç°ç»†èŠ‚](#å®ç°ç»†èŠ‚)
8. [ä¸å…¶ä»–æ¡†æ¶å¯¹æ¯”](#ä¸å…¶ä»–æ¡†æ¶å¯¹æ¯”)

---

## ğŸ¯ æ¡†æ¶æ¦‚è¿°

### ä»€ä¹ˆæ˜¯ LeRobotï¼Ÿ

**LeRobot** æ˜¯ Hugging Face å¼€å‘çš„å¼€æºæœºå™¨äººå­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è®©æœºå™¨äººå­¦ä¹ ï¼ˆç‰¹åˆ«æ˜¯æ¨¡ä»¿å­¦ä¹ ï¼‰åƒä½¿ç”¨ Transformers åº“ä¸€æ ·ç®€å•ã€‚

### æ ¸å¿ƒç†å¿µ

```
æ•°æ®é‡‡é›† â†’ æ•°æ®é›†æ ‡å‡†åŒ– â†’ ç­–ç•¥è®­ç»ƒ â†’ æ¨¡å‹éƒ¨ç½²
   â†“           â†“              â†“          â†“
 çœŸå®/ä»¿çœŸ   ç»Ÿä¸€æ ¼å¼      å¤šç§ç®—æ³•    ä¸€é”®æ¨ç†
```

### å…³é”®ç‰¹æ€§

âœ… **ç»Ÿä¸€æ¥å£**ï¼šç±»ä¼¼ Hugging Face Transformersï¼Œæä¾›ç»Ÿä¸€çš„ API
âœ… **å¼€ç®±å³ç”¨**ï¼šé¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†ï¼Œç›´æ¥åŠ è½½ä½¿ç”¨
âœ… **ç¡¬ä»¶é›†æˆ**ï¼šåŸç”Ÿæ”¯æŒå¤šç§æœºæ¢°è‡‚å’Œæ‘„åƒå¤´
âœ… **æ¨¡å—åŒ–è®¾è®¡**ï¼šç­–ç•¥ã€æ•°æ®é›†ã€æœºå™¨äººæ¥å£è§£è€¦
âœ… **ç¤¾åŒºé©±åŠ¨**ï¼šä¸ Hugging Face Hub æ·±åº¦é›†æˆ

---

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### æ¡†æ¶ç»“æ„å›¾

```
LeRobot æ¡†æ¶
â”‚
â”œâ”€â”€ ğŸ“¦ Datasets (æ•°æ®å±‚)
â”‚   â”œâ”€â”€ LeRobotDataset - ç»Ÿä¸€æ•°æ®é›†æ¥å£
â”‚   â”œâ”€â”€ æ•°æ®åŠ è½½å™¨
â”‚   â””â”€â”€ æ•°æ®é¢„å¤„ç†
â”‚
â”œâ”€â”€ ğŸ¤– Robots (ç¡¬ä»¶å±‚)
â”‚   â”œâ”€â”€ æœºæ¢°è‡‚æ§åˆ¶
â”‚   â”‚   â”œâ”€â”€ SO100/SO101 (Feetech)
â”‚   â”‚   â”œâ”€â”€ Koch (Dynamixel)
â”‚   â”‚   â””â”€â”€ Aloha
â”‚   â”œâ”€â”€ æ‘„åƒå¤´æ¥å£
â”‚   â”‚   â”œâ”€â”€ OpenCV
â”‚   â”‚   â””â”€â”€ Intel RealSense
â”‚   â””â”€â”€ é¥æ“ä½œå™¨
â”‚
â”œâ”€â”€ ğŸ§  Policies (ç­–ç•¥å±‚)
â”‚   â”œâ”€â”€ ACT (Action Chunking Transformer)
â”‚   â”œâ”€â”€ Diffusion Policy
â”‚   â”œâ”€â”€ SmolVLA (Vision-Language-Action)
â”‚   â”œâ”€â”€ GR00T (NVIDIA)
â”‚   â”œâ”€â”€ pi_0 / pi_0.5
â”‚   â”œâ”€â”€ VQ-BeT
â”‚   â””â”€â”€ TD-MPC
â”‚
â”œâ”€â”€ ğŸ”§ Training (è®­ç»ƒå±‚)
â”‚   â”œâ”€â”€ è®­ç»ƒå¾ªç¯
â”‚   â”œâ”€â”€ ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
â”‚   â””â”€â”€ æ—¥å¿—è®°å½• (W&B)
â”‚
â””â”€â”€ ğŸš€ Deployment (éƒ¨ç½²å±‚)
    â”œâ”€â”€ å®æ—¶æ¨ç†
    â”œâ”€â”€ å¼‚æ­¥æ¨ç†æœåŠ¡
    â””â”€â”€ æ¨¡å‹å¯¼å‡º
```

### ç›®å½•ç»“æ„

```
lerobot/
â”œâ”€â”€ cameras/              # æ‘„åƒå¤´é©±åŠ¨
â”‚   â”œâ”€â”€ opencv/
â”‚   â””â”€â”€ intelrealsense/
â”‚
â”œâ”€â”€ datasets/             # æ•°æ®é›†å·¥å…·
â”‚   â”œâ”€â”€ lerobot_dataset.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ v3/              # æ•°æ®é›†ç‰ˆæœ¬
â”‚
â”œâ”€â”€ policies/            # ç­–ç•¥å®ç°
â”‚   â”œâ”€â”€ act/             # ACT æ¨¡å‹
â”‚   â”œâ”€â”€ diffusion/       # Diffusion Policy
â”‚   â”œâ”€â”€ smolvla/         # SmolVLA æ¨¡å‹
â”‚   â”œâ”€â”€ groot/           # NVIDIA GR00T
â”‚   â”œâ”€â”€ pi0/             # Ï€â‚€ æ¨¡å‹
â”‚   â””â”€â”€ vqbet/           # VQ-BeT
â”‚
â”œâ”€â”€ robots/              # æœºå™¨äººæ¥å£
â”‚   â”œâ”€â”€ so100_follower/
â”‚   â”œâ”€â”€ so101_follower/
â”‚   â”œâ”€â”€ koch/
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ teleoperators/       # é¥æ“ä½œæ¥å£
â”‚   â”œâ”€â”€ so100_leader/
â”‚   â”œâ”€â”€ so101_leader/
â”‚   â””â”€â”€ keyboard/
â”‚
â”œâ”€â”€ scripts/             # å‘½ä»¤è¡Œå·¥å…·
â”‚   â”œâ”€â”€ lerobot_train.py
â”‚   â”œâ”€â”€ lerobot_record.py
â”‚   â”œâ”€â”€ lerobot_calibrate.py
â”‚   â””â”€â”€ lerobot_setup_motors.py
â”‚
â”œâ”€â”€ async_inference/     # å¼‚æ­¥æ¨ç†
â”‚   â”œâ”€â”€ policy_server.py
â”‚   â””â”€â”€ robot_client.py
â”‚
â””â”€â”€ configs/             # é…ç½®æ–‡ä»¶
    â”œâ”€â”€ policies/
    â””â”€â”€ default.yaml
```

---

## ğŸ” å…³é”®æ¨¡å—è¯¦è§£

### 1. æ•°æ®é›†æ¨¡å— (`datasets/`)

#### LeRobotDataset ç±»

**ä½œç”¨**ï¼šç»Ÿä¸€çš„æ•°æ®é›†æ¥å£ï¼Œæ”¯æŒæœ¬åœ°å’Œ Hub æ•°æ®é›†

**æ ¸å¿ƒåŠŸèƒ½**ï¼š

```python
from lerobot.datasets import LeRobotDataset

# ä» Hub åŠ è½½
dataset = LeRobotDataset("lerobot/aloha_sim_insertion_human")

# ä»æœ¬åœ°åŠ è½½
dataset = LeRobotDataset("/path/to/dataset")

# è®¿é—®æ•°æ®
sample = dataset[0]  # è·å–ç¬¬ä¸€å¸§
# sample åŒ…å«ï¼š
# - observation.images.* : å›¾åƒè§‚æµ‹
# - observation.state : çŠ¶æ€è§‚æµ‹ (å…³èŠ‚ä½ç½®ç­‰)
# - action : åŠ¨ä½œ
# - episode_index : episode ç´¢å¼•
# - frame_index : å¸§ç´¢å¼•
```

#### æ•°æ®é›†ç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **ç»Ÿä¸€æ ¼å¼** | æ‰€æœ‰æ•°æ®é›†éµå¾ªç›¸åŒçš„ç»“æ„ |
| **Lazy Loading** | æŒ‰éœ€åŠ è½½ï¼ŒèŠ‚çœå†…å­˜ |
| **è‡ªåŠ¨ä¸‹è½½** | ä» Hub è‡ªåŠ¨ä¸‹è½½å¹¶ç¼“å­˜ |
| **ç‰ˆæœ¬æ§åˆ¶** | æ”¯æŒæ•°æ®é›†ç‰ˆæœ¬ (v3) |
| **å¤šæ¨¡æ€** | å›¾åƒã€çŠ¶æ€ã€è¯­è¨€ã€åŠ¨ä½œ |

#### æ•°æ®ç»“æ„

```python
{
    "observation": {
        "images": {
            "front": torch.Tensor,  # [H, W, 3]
            "wrist": torch.Tensor,  # [H, W, 3]
        },
        "state": torch.Tensor,      # [state_dim]
    },
    "action": torch.Tensor,         # [action_dim]
    "episode_index": int,
    "frame_index": int,
    "timestamp": float,
    "next.reward": float,           # å¯é€‰
    "next.done": bool,              # å¯é€‰
}
```

---

### 2. æœºå™¨äººæ¨¡å— (`robots/`)

#### æœºå™¨äººæŠ½è±¡åŸºç±»

**è®¾è®¡æ¨¡å¼**ï¼šæ¯ä¸ªæœºå™¨äººå®ç°ç»Ÿä¸€æ¥å£

```python
class Robot:
    def connect(self) -> None:
        """è¿æ¥æœºå™¨äººç¡¬ä»¶"""

    def disconnect(self) -> None:
        """æ–­å¼€è¿æ¥"""

    def get_observation(self) -> dict:
        """è·å–å½“å‰è§‚æµ‹ï¼ˆçŠ¶æ€ + å›¾åƒï¼‰"""

    def send_action(self, action: dict) -> None:
        """å‘é€åŠ¨ä½œåˆ°æœºå™¨äºº"""

    def calibrate(self) -> None:
        """æ ‡å®šæœºå™¨äºº"""
```

#### SO101 ç¤ºä¾‹

```python
from lerobot.robots.so101_follower import SO101Follower, SO101FollowerConfig
from lerobot.cameras.opencv import OpenCVCameraConfig

# é…ç½®
config = SO101FollowerConfig(
    port="/dev/ttyACM0",
    id="my_robot",
    cameras={
        "front": OpenCVCameraConfig(
            index_or_path=0,
            width=640,
            height=480,
            fps=30,
        )
    }
)

# åˆ›å»ºæœºå™¨äºº
robot = SO101Follower(config)

# è¿æ¥
robot.connect()

# è·å–è§‚æµ‹
obs = robot.get_observation()
# obs = {
#     "observation.state": np.array([...]),  # å…³èŠ‚ä½ç½®
#     "observation.images.front": np.array([...]),  # å›¾åƒ
# }

# å‘é€åŠ¨ä½œ
action = {"action": np.array([...])}
robot.send_action(action)

# æ–­å¼€
robot.disconnect()
```

---

### 3. ç­–ç•¥æ¨¡å— (`policies/`)

#### ç­–ç•¥æŠ½è±¡åŸºç±»

```python
class PreTrainedPolicy:
    @classmethod
    def from_pretrained(cls, path: str):
        """ä»é¢„è®­ç»ƒæ¨¡å‹åŠ è½½"""

    def forward(self, batch: dict) -> dict:
        """å‰å‘ä¼ æ’­ï¼ˆè®­ç»ƒï¼‰"""

    def select_action(self, obs: dict) -> torch.Tensor:
        """é€‰æ‹©åŠ¨ä½œï¼ˆæ¨ç†ï¼‰"""

    def save_pretrained(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
```

#### æ”¯æŒçš„ç­–ç•¥åˆ—è¡¨

| ç­–ç•¥ | ç±»å‹ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **ACT** | Transformer | åŠ¨ä½œåˆ†å—ï¼Œè”åˆè®­ç»ƒ | åŒè‡‚æ“ä½œï¼Œç²¾ç»†æ§åˆ¶ |
| **Diffusion** | æ‰©æ•£æ¨¡å‹ | å¤šæ¨¡æ€ï¼Œç¨³å®šè®­ç»ƒ | å¤æ‚ä»»åŠ¡ï¼Œå¤šæ ·æ€§ |
| **SmolVLA** | VLM + Expert | è¯­è¨€æ¡ä»¶ï¼Œè¿ç§»èƒ½åŠ› | è¯­è¨€å¼•å¯¼ä»»åŠ¡ |
| **GR00T** | Transformer | NVIDIA å¤§æ¨¡å‹ | é€šç”¨æœºå™¨äººä»»åŠ¡ |
| **Ï€â‚€ / Ï€â‚€.5** | VLM | é¢„è®­ç»ƒï¼Œzero-shot | è·¨æœºå™¨äººè¿ç§» |
| **VQ-BeT** | VQ-VAE + Transformer | ç¦»æ•£åŒ–åŠ¨ä½œ | é•¿åºåˆ—ä»»åŠ¡ |
| **TD-MPC** | å¼ºåŒ–å­¦ä¹  | æ¨¡å‹é¢„æµ‹æ§åˆ¶ | åœ¨çº¿å­¦ä¹  |

#### ACT æ¶æ„æ¦‚è§ˆ

```
è¾“å…¥: [è§‚æµ‹å›¾åƒ, çŠ¶æ€, åŠ¨ä½œå†å²]
  â†“
[è§†è§‰ç¼–ç å™¨ (ResNet/ViT)]
  â†“
[Transformer Encoder]
  â†“
[Transformer Decoder] â† [åŠ¨ä½œæŸ¥è¯¢ (Learnable)]
  â†“
è¾“å‡º: [åŠ¨ä½œå— (Action Chunk)]
```

---

### 4. è®­ç»ƒæ¨¡å— (`scripts/`)

#### è®­ç»ƒå‘½ä»¤

```bash
lerobot-train \
  --policy.type=act \
  --policy.path=lerobot/act_so100_pickplace \  # å¯é€‰ï¼šä»é¢„è®­ç»ƒåŠ è½½
  --dataset.repo_id=lerobot/aloha_sim_insertion_human \
  --batch_size=8 \
  --steps=100000 \
  --output_dir=outputs/train/act \
  --wandb.enable=true
```

#### è®­ç»ƒæµç¨‹

```python
# ä¼ªä»£ç 
for step in range(total_steps):
    # æ¯ä¸€æ¬¡å¾ªç¯å°±åƒâ€œè®­ç»ƒæ—¥è®°â€çš„ä¸€é¡µï¼šåšä¸€æ¬¡ç»ƒä¹ å¹¶å¤ç›˜
    # 1. é‡‡æ ·æ‰¹æ¬¡ â€”â€” åƒä»ç»ƒä¹ å†ŒæŠ½ä¸€é¡µé¢˜ç›®ï¼ˆå–ä¸€æ‰¹æ•°æ®ï¼‰
    batch = dataloader.sample()

    # 2. å‰å‘ä¼ æ’­ â€”â€” åƒâ€œåšé¢˜â€ï¼šæŠŠé¢˜ç›®ï¼ˆbatchï¼‰å–‚ç»™ç­–ç•¥ï¼Œå¾—åˆ°ç­”æ¡ˆ
    output = policy(batch)

    # 3. è®¡ç®—æŸå¤± â€”â€” åƒâ€œå¯¹ç­”æ¡ˆâ€ï¼šå’Œæ ‡å‡†ç­”æ¡ˆæ¯”å¯¹ï¼Œçœ‹çœ‹é”™äº†å¤šå°‘ï¼ˆè¯¯å·®ï¼‰
    loss = criterion(output["actions"], batch["action"])

    # 4. åå‘ä¼ æ’­ â€”â€” åƒâ€œæ‰¾åˆ°é”™å› å¹¶é€šçŸ¥æ¯ä¸ªæ­¥éª¤è¯¥æ€ä¹ˆæ”¹â€ï¼ˆæŠŠè¯¯å·®å¾€å›ä¼ ï¼‰
    loss.backward()

    # 5. ä¼˜åŒ–å™¨æ­¥è¿› â€”â€” åƒâ€œè°ƒæ•´æ–¹æ³•â€ï¼šæ ¹æ®åé¦ˆå¾®è°ƒå‚æ•°ï¼›
    #    æ¸…é›¶æ¢¯åº¦åˆ™åƒæ“¦å¹²å‡€é»‘æ¿ï¼Œé¿å…ä¸Šä¸€æ¬¡çš„ç²‰ç¬”ç°å½±å“ä¸‹ä¸€æ¬¡ç»ƒä¹ 
    optimizer.step()
    optimizer.zero_grad()

    # 6. æ—¥å¿—è®°å½• â€”â€” åƒâ€œè®°å­¦ä¹ æ›²çº¿â€ï¼šå®šæœŸæŠŠåˆ†æ•°å†™è¿›æ—¥å¿—æ–¹ä¾¿å¤ç›˜
    if step % log_freq == 0:
        wandb.log({"loss": loss.item()})

    # 7. ä¿å­˜æ£€æŸ¥ç‚¹ â€”â€” åƒâ€œæ¸¸æˆå­˜æ¡£â€ï¼šåˆ°è¾¾é‡Œç¨‹ç¢‘å°±ä¿å­˜ï¼Œé˜²æ­¢è¿›åº¦ä¸¢å¤±
    if step % save_freq == 0:
        policy.save_pretrained(f"checkpoint-{step}")
```

---

### 5. æ•°æ®é‡‡é›†æ¨¡å—

#### å½•åˆ¶æ•°æ®

```bash
lerobot-record \
  --robot.type=so101_follower \
  --robot.port=/dev/ttyACM0 \
  --robot.id=my_robot \
  --robot.cameras="{front: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}}" \
  --teleop.type=so101_leader \
  --teleop.port=/dev/ttyACM1 \
  --teleop.id=my_leader \
  --dataset.repo_id=username/my_dataset \
  --dataset.num_episodes=50 \
  --dataset.episode_time_s=30 \
  --dataset.single_task="Pick the cube and place it on the plate."
```

#### æ•°æ®é‡‡é›†æµç¨‹

```
1. åˆå§‹åŒ–æœºå™¨äººå’Œé¥æ“ä½œå™¨
   â†“
2. å¼€å§‹ Episode
   â†“
3. å¾ªç¯é‡‡é›†:
   - è¯»å–ä¸»è‡‚çŠ¶æ€ (é¥æ“ä½œè¾“å…¥)
   - å‘é€åˆ°ä»è‡‚ (æ‰§è¡ŒåŠ¨ä½œ)
   - è®°å½•è§‚æµ‹å’ŒåŠ¨ä½œ
   - å­˜å‚¨åˆ°ç¼“å†²åŒº
   â†“
4. Episode ç»“æŸ
   - ä¿å­˜åˆ°æ•°æ®é›†
   - æ›´æ–°å…ƒæ•°æ®
   â†“
5. é‡å¤æ­¥éª¤ 2-4ï¼Œç›´åˆ°å®Œæˆæ‰€æœ‰ episodes
   â†“
6. ä¸Šä¼ åˆ° Hugging Face Hub (å¯é€‰)
```

---

## ğŸ”„ æ•°æ®æµç¨‹

### å®Œæ•´æ•°æ®æµ

```
ç‰©ç†ä¸–ç•Œ
    â†“ [ä¼ æ„Ÿå™¨]
[è§‚æµ‹æ•°æ®]
    â†“
[æ•°æ®é‡‡é›†ç³»ç»Ÿ]
    â”œâ”€ å›¾åƒ: OpenCV/RealSense
    â”œâ”€ çŠ¶æ€: ç”µæœºç¼–ç å™¨
    â””â”€ åŠ¨ä½œ: ä¸»è‡‚è¯»å–
    â†“
[LeRobotDataset]
    â”œâ”€ æœ¬åœ°å­˜å‚¨ (Parquet)
    â””â”€ Hub ä¸Šä¼ 
    â†“
[DataLoader]
    â”œâ”€ æ‰¹æ¬¡é‡‡æ ·
    â”œâ”€ æ•°æ®å¢å¼º
    â””â”€ å½’ä¸€åŒ–
    â†“
[ç­–ç•¥ç½‘ç»œ]
    â”œâ”€ ç¼–ç å™¨: å›¾åƒ â†’ ç‰¹å¾
    â”œâ”€ çŠ¶æ€ç¼–ç : MLP
    â””â”€ è§£ç å™¨: ç‰¹å¾ â†’ åŠ¨ä½œ
    â†“
[è®­ç»ƒ/æ¨ç†]
    â”œâ”€ è®­ç»ƒ: æŸå¤± â†’ æ¢¯åº¦ â†’ ä¼˜åŒ–
    â””â”€ æ¨ç†: è§‚æµ‹ â†’ åŠ¨ä½œ
    â†“
[æœºå™¨äººæ‰§è¡Œ]
    â””â”€ åŠ¨ä½œ â†’ ç”µæœºæ§åˆ¶
    â†“
ç‰©ç†ä¸–ç•Œ
```

### æ•°æ®æ ¼å¼è½¬æ¢

```python
# åŸå§‹æ•°æ® (æœºå™¨äºº)
raw_obs = {
    "joint_positions": np.array([...]),  # å¼§åº¦
    "images": {
        "front": np.array([H, W, 3]),    # uint8, BGR
    }
}

# â†“ [æ•°æ®é›†å­˜å‚¨]

# Parquet æ ¼å¼
stored_data = {
    "observation.state": np.array([...]),
    "observation.images.front": np.array([...]),  # å‹ç¼©åçš„å›¾åƒ
    "action": np.array([...]),
}

# â†“ [è®­ç»ƒæ—¶åŠ è½½]

# Tensor æ ¼å¼ (å½’ä¸€åŒ–)
batch = {
    "observation.state": torch.Tensor([...]),    # å½’ä¸€åŒ–åˆ° [-1, 1]
    "observation.images.front": torch.Tensor([...]),  # å½’ä¸€åŒ–åˆ° [0, 1]
    "action": torch.Tensor([...]),               # å½’ä¸€åŒ–
}
```

---

## ğŸ¯ ä¼˜ç¼ºç‚¹åˆ†æ

### âœ… ä¼˜ç‚¹

#### 1. **æ˜“ç”¨æ€§**

**ç»Ÿä¸€ API**ï¼š
```python
# åŠ è½½æ•°æ®é›† - å’Œ Hugging Face Datasets ä¸€æ ·ç®€å•
dataset = LeRobotDataset("lerobot/aloha_sim_insertion_human")

# åŠ è½½æ¨¡å‹ - å’Œ Transformers ä¸€æ ·ç®€å•
policy = ACTPolicy.from_pretrained("lerobot/act_aloha_sim_insertion_human")

# æ¨ç† - ä¸€è¡Œä»£ç 
action = policy.select_action(observation)
```

#### 2. **æ¨¡å—åŒ–**

- **è§£è€¦è®¾è®¡**ï¼šæ•°æ®ã€ç­–ç•¥ã€æœºå™¨äººç‹¬ç«‹
- **æ˜“äºæ‰©å±•**ï¼šæ·»åŠ æ–°ç­–ç•¥/æœºå™¨äººåªéœ€å®ç°æ¥å£
- **å¯ç»„åˆ**ï¼šä»»æ„ç­–ç•¥ + ä»»æ„æ•°æ®é›† + ä»»æ„æœºå™¨äºº

#### 3. **ç¤¾åŒºç”Ÿæ€**

- **Hugging Face Hub é›†æˆ**ï¼š
  - æ•°æ®é›†æ‰˜ç®¡å’Œç‰ˆæœ¬æ§åˆ¶
  - æ¨¡å‹åˆ†äº«å’Œä¸‹è½½
  - è‡ªåŠ¨ç¼“å­˜
- **å¼€æºç¤¾åŒº**ï¼šæ´»è·ƒçš„å¼€å‘å’Œæ”¯æŒ

#### 4. **ç¡¬ä»¶æ”¯æŒ**

- **å¤šç§æœºæ¢°è‡‚**ï¼šSO100/101, Koch, Aloha
- **å¤šç§æ‘„åƒå¤´**ï¼šOpenCV, Intel RealSense
- **æ ‡å‡†åŒ–æ¥å£**ï¼šæ˜“äºæ·»åŠ æ–°ç¡¬ä»¶

#### 5. **å¯é‡ç°æ€§**

- **é…ç½®æ–‡ä»¶**ï¼šæ‰€æœ‰å‚æ•°å¯è¿½æº¯
- **ç‰ˆæœ¬æ§åˆ¶**ï¼šæ•°æ®é›†å’Œæ¨¡å‹ç‰ˆæœ¬åŒ–
- **ç¡®å®šæ€§è®­ç»ƒ**ï¼šå¯è®¾ç½®éšæœºç§å­

---

### âŒ ç¼ºç‚¹

#### 1. **å­¦ä¹ æ›²çº¿**

- **å¤šå±‚æŠ½è±¡**ï¼šéœ€è¦ç†è§£å¤šä¸ªæ¦‚å¿µï¼ˆDataset, Policy, Robotï¼‰
- **é…ç½®å¤æ‚**ï¼šYAML é…ç½®æ–‡ä»¶è¾ƒå¤š
- **æ–‡æ¡£åˆ†æ•£**ï¼šéƒ¨åˆ†é«˜çº§åŠŸèƒ½æ–‡æ¡£ä¸å…¨

#### 2. **æ€§èƒ½å¼€é”€**

- **æŠ½è±¡å±‚**ï¼šç»Ÿä¸€æ¥å£å¸¦æ¥é¢å¤–å¼€é”€
- **æ•°æ®åŠ è½½**ï¼šå¯¹äºå¤§è§„æ¨¡æ•°æ®é›†å¯èƒ½è¾ƒæ…¢
- **å®æ—¶æ€§**ï¼šæ¨ç†å»¶è¿Ÿç›¸æ¯”æ‰‹å†™ä»£ç ç¨é«˜

#### 3. **ä¾èµ–é—®é¢˜**

- **ä¾èµ–å¤š**ï¼šéœ€è¦å®‰è£…å¤šä¸ªåº“ï¼ˆPyTorch, OpenCV, transformers ç­‰ï¼‰
- **ç‰ˆæœ¬å†²çª**ï¼šä¸åŒç­–ç•¥å¯èƒ½æœ‰ä¸åŒä¾èµ–
- **ç¡¬ä»¶ä¾èµ–**ï¼šéƒ¨åˆ†åŠŸèƒ½éœ€è¦ç‰¹å®šç¡¬ä»¶ï¼ˆGPU, ç‰¹å®šæ‘„åƒå¤´ï¼‰

#### 4. **çµæ´»æ€§é™åˆ¶**

- **æ¡†æ¶çº¦æŸ**ï¼šå¿…é¡»éµå¾ªæ¡†æ¶çš„æ•°æ®æ ¼å¼å’Œæ¥å£
- **å®šåˆ¶å›°éš¾**ï¼šæ·±åº¦å®šåˆ¶éœ€è¦ä¿®æ”¹æ¡†æ¶ä»£ç 
- **ç­–ç•¥é™åˆ¶**ï¼šéƒ¨åˆ†ç­–ç•¥ä¸æ”¯æŒæŸäº›åŠŸèƒ½ï¼ˆå¦‚åœ¨çº¿å­¦ä¹ ï¼‰

#### 5. **ç”Ÿäº§éƒ¨ç½²**

- **ä¼˜åŒ–ä¸è¶³**ï¼šç¼ºå°‘æ¨¡å‹é‡åŒ–ã€å‰ªæç­‰ä¼˜åŒ–
- **éƒ¨ç½²å·¥å…·**ï¼šéƒ¨ç½²åˆ°åµŒå…¥å¼è®¾å¤‡æ”¯æŒæœ‰é™
- **å®æ—¶ä¿è¯**ï¼šæ²¡æœ‰ç¡¬å®æ—¶ä¿è¯

---

### ğŸ†š ä¸å…¶ä»–æ¡†æ¶å¯¹æ¯”

| ç‰¹æ€§ | LeRobot | RoboSuite | Robomimic | ManiSkill |
|------|---------|-----------|-----------|-----------|
| **æ˜“ç”¨æ€§** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­ |
| **ç¡¬ä»¶æ”¯æŒ** | â­â­â­â­ | â­â­ | â­â­â­ | â­â­ |
| **ç­–ç•¥ä¸°å¯Œåº¦** | â­â­â­â­ | â­â­ | â­â­â­â­â­ | â­â­â­ |
| **ç¤¾åŒºç”Ÿæ€** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­ |
| **ä»¿çœŸç¯å¢ƒ** | â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ |
| **çœŸå®æœºå™¨äºº** | â­â­â­â­â­ | â­ | â­â­â­ | â­ |

---

## ğŸ› ï¸ å®ç°ç»†èŠ‚

### 1. æ•°æ®å­˜å‚¨æ ¼å¼

LeRobot ä½¿ç”¨ **Parquet** æ ¼å¼å­˜å‚¨æ•°æ®ï¼š

```
dataset/
â”œâ”€â”€ meta/
â”‚   â”œâ”€â”€ info.json          # æ•°æ®é›†å…ƒæ•°æ®
â”‚   â”œâ”€â”€ episodes.jsonl     # Episode ä¿¡æ¯
â”‚   â””â”€â”€ tasks.jsonl        # ä»»åŠ¡æè¿°
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chunk-000/
â”‚   â”‚   â”œâ”€â”€ observation.state.parquet
â”‚   â”‚   â”œâ”€â”€ action.parquet
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ chunk-001/
â””â”€â”€ videos/
    â”œâ”€â”€ episode_000000/
    â”‚   â”œâ”€â”€ front.mp4
    â”‚   â””â”€â”€ wrist.mp4
    â””â”€â”€ episode_000001/
```

**ä¼˜ç‚¹**ï¼š
- âœ… åˆ—å¼å­˜å‚¨ï¼Œé«˜æ•ˆæŸ¥è¯¢
- âœ… å‹ç¼©ç‡é«˜
- âœ… æ”¯æŒæµå¼è¯»å–

### 2. å›¾åƒå¤„ç†

```python
# å›¾åƒç¼–ç æµç¨‹
åŸå§‹å›¾åƒ (H, W, 3) uint8
    â†“ [å‹ç¼©]
JPEG/PNG å­—èŠ‚
    â†“ [å­˜å‚¨åˆ° Parquet]
æ•°æ®åº“
    â†“ [åŠ è½½æ—¶è§£å‹]
PIL Image
    â†“ [è½¬æ¢ + å½’ä¸€åŒ–]
Tensor (3, H, W) float32 âˆˆ [0, 1]
```

### 3. åŠ¨ä½œå½’ä¸€åŒ–

```python
class Normalization:
    def __init__(self, mode: str):
        self.mode = mode  # "mean_std", "min_max", "identity"

    def normalize(self, x: np.ndarray) -> np.ndarray:
        if self.mode == "mean_std":
            return (x - self.mean) / self.std
        elif self.mode == "min_max":
            return (x - self.min) / (self.max - self.min) * 2 - 1
        else:  # identity
            return x

    def unnormalize(self, x: np.ndarray) -> np.ndarray:
        # åå‘æ“ä½œ
        ...
```

### 4. è®­ç»ƒå¾ªç¯æ ¸å¿ƒä»£ç 

```python
def train(policy, dataloader, optimizer, num_steps):
    policy.train()

    for step in range(num_steps):
        # é‡‡æ ·æ‰¹æ¬¡
        batch = next(dataloader)
        batch = {k: v.to(device) for k, v in batch.items()}

        # å‰å‘ä¼ æ’­
        output = policy(batch)

        # è®¡ç®—æŸå¤±
        loss = F.mse_loss(output["action"], batch["action"])

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()

        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(
            policy.parameters(),
            max_norm=10.0
        )

        # ä¼˜åŒ–å™¨æ­¥è¿›
        optimizer.step()

        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()

        # æ—¥å¿—
        if step % 100 == 0:
            print(f"Step {step}, Loss: {loss.item():.4f}")
```

### 5. æ¨ç†ä¼˜åŒ–

```python
@torch.no_grad()
def inference(policy, observation):
    policy.eval()

    # é¢„å¤„ç†
    obs = preprocess(observation)
    obs = {k: v.unsqueeze(0).to(device) for k, v in obs.items()}

    # æ¨ç†
    action = policy.select_action(obs)

    # åå¤„ç†
    action = postprocess(action)

    return action.cpu().numpy()
```

---

## ğŸ“Š å…³é”®æŒ‡æ ‡

### è®­ç»ƒæ€§èƒ½

| æ¨¡å‹ | å‚æ•°é‡ | è®­ç»ƒæ—¶é—´ (100k steps) | GPU æ˜¾å­˜ | Batch Size |
|------|--------|----------------------|----------|------------|
| ACT | ~10M | ~2å°æ—¶ @ A100 | ~8GB | 8 |
| Diffusion | ~50M | ~8å°æ—¶ @ A100 | ~16GB | 16 |
| SmolVLA | ~450M | ~20å°æ—¶ @ A100 | ~40GB | 64 |

### æ¨ç†æ€§èƒ½

| æ¨¡å‹ | å»¶è¿Ÿ (ms) | FPS | GPU |
|------|----------|-----|-----|
| ACT | ~10ms | ~100 | RTX 3090 |
| Diffusion | ~50ms | ~20 | RTX 3090 |
| SmolVLA | ~30ms | ~33 | RTX 3090 |

---

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹

### 5 åˆ†é’Ÿå¿«é€Ÿç¤ºä¾‹

```python
# 1. å®‰è£…
# pip install lerobot

# 2. åŠ è½½æ•°æ®é›†
from lerobot.datasets import LeRobotDataset
dataset = LeRobotDataset("lerobot/aloha_sim_insertion_human")

# 3. æŸ¥çœ‹æ•°æ®
sample = dataset[0]
print(sample.keys())

# 4. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
from lerobot.policies.act import ACTPolicy
policy = ACTPolicy.from_pretrained("lerobot/act_aloha_sim_insertion_human")

# 5. æ¨ç†
action = policy.select_action(sample)
print(action.shape)
```

---

## ğŸ“š è¿›é˜¶ä¸»é¢˜

### è‡ªå®šä¹‰ç­–ç•¥

```python
from lerobot.policies.pretrained import PreTrainedPolicy

class MyPolicy(PreTrainedPolicy):
    def __init__(self, config):
        super().__init__(config)
        # å®šä¹‰ç½‘ç»œ

    def forward(self, batch):
        # è®­ç»ƒæ—¶çš„å‰å‘ä¼ æ’­
        pass

    def select_action(self, obs):
        # æ¨ç†æ—¶é€‰æ‹©åŠ¨ä½œ
        pass
```

### è‡ªå®šä¹‰æœºå™¨äºº

```python
from lerobot.robots import Robot

class MyRobot(Robot):
    def connect(self):
        # è¿æ¥ç¡¬ä»¶
        pass

    def get_observation(self):
        # è¯»å–è§‚æµ‹
        pass

    def send_action(self, action):
        # å‘é€åŠ¨ä½œ
        pass
```

---

## ğŸ“ å­¦ä¹ èµ„æº

### å®˜æ–¹èµ„æº

- **æ–‡æ¡£**: https://huggingface.co/docs/lerobot
- **GitHub**: https://github.com/huggingface/lerobot
- **è®ºå›**: https://discuss.huggingface.co/
- **Discord**: https://discord.com/invite/s3KuuzsPFb

### æ•™ç¨‹

- **å®˜æ–¹æ•™ç¨‹**: LeRobot Notebooks
- **è§†é¢‘æ•™ç¨‹**: YouTube - Hugging Face
- **åšå®¢**: Hugging Face Blog

---

## ğŸ’¡ æœ€ä½³å®è·µ

### æ•°æ®é‡‡é›†

1. âœ… é‡‡é›†è¶³å¤Ÿçš„æ•°æ®ï¼ˆ50+ episodesï¼‰
2. âœ… åŒ…å«ä»»åŠ¡å˜åŒ–
3. âœ… ä¿æŒç¯å¢ƒä¸€è‡´æ€§
4. âœ… éªŒè¯æ•°æ®è´¨é‡

### è®­ç»ƒ

1. âœ… ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
2. âœ… ç›‘æ§è®­ç»ƒæ›²çº¿
3. âœ… å®šæœŸè¯„ä¼°
4. âœ… ä¿å­˜å¤šä¸ªæ£€æŸ¥ç‚¹

### éƒ¨ç½²

1. âœ… å…ˆåœ¨ä»¿çœŸæµ‹è¯•
2. âœ… é€æ­¥å¢åŠ å¤æ‚åº¦
3. âœ… å®‰å…¨ç¬¬ä¸€
4. âœ… è®°å½•å¤±è´¥æ¡ˆä¾‹

---

## ğŸ”® æœªæ¥æ–¹å‘

LeRobot æ­£åœ¨å‘å±•çš„æ–¹å‘ï¼š

1. **æ›´å¤šç­–ç•¥**ï¼šæŒç»­æ·»åŠ æœ€æ–°çš„ç­–ç•¥
2. **ç¡¬ä»¶æ”¯æŒ**ï¼šæ›´å¤šæœºå™¨äººå¹³å°
3. **ä¼˜åŒ–å·¥å…·**ï¼šæ¨¡å‹å‹ç¼©ã€åŠ é€Ÿ
4. **ä»¿çœŸé›†æˆ**ï¼šæ›´å¥½çš„ sim2real
5. **å¤šä»»åŠ¡å­¦ä¹ **ï¼šé€šç”¨æœºå™¨äººæ¨¡å‹

---

**æ€»ç»“**ï¼šLeRobot æ˜¯ä¸€ä¸ªæ˜“ç”¨ã€æ¨¡å—åŒ–ã€ç¤¾åŒºé©±åŠ¨çš„æœºå™¨äººå­¦ä¹ æ¡†æ¶ï¼Œç‰¹åˆ«é€‚åˆå¿«é€ŸåŸå‹å¼€å‘å’Œç ”ç©¶ã€‚è™½ç„¶æœ‰ä¸€äº›æ€§èƒ½å¼€é”€å’Œçµæ´»æ€§é™åˆ¶ï¼Œä½†å…¶ç»Ÿä¸€çš„ API å’Œä¸°å¯Œçš„ç”Ÿæ€ç³»ç»Ÿä½¿å…¶æˆä¸ºæœºå™¨äººå­¦ä¹ å…¥é—¨å’Œåº”ç”¨çš„ä¼˜ç§€é€‰æ‹©ã€‚
