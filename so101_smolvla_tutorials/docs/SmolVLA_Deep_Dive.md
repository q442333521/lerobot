# SmolVLA æ·±åº¦è§£æï¼šåŸç†ã€ä¼˜ç¼ºç‚¹ä¸å®ç°

> **å…¨é¢æŒæ¡ SmolVLAï¼šè½»é‡çº§è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹**

---

## ğŸ“‹ ç›®å½•

1. [SmolVLA æ¦‚è¿°](#smolvla-æ¦‚è¿°)
2. [æ ¸å¿ƒåŸç†](#æ ¸å¿ƒåŸç†)
3. [æ¶æ„è¯¦è§£](#æ¶æ„è¯¦è§£)
4. [ä¼˜ç¼ºç‚¹åˆ†æ](#ä¼˜ç¼ºç‚¹åˆ†æ)
5. [å®ç°ç»†èŠ‚](#å®ç°ç»†èŠ‚)
6. [è®­ç»ƒç­–ç•¥](#è®­ç»ƒç­–ç•¥)
7. [ä¸å…¶ä»–æ¨¡å‹å¯¹æ¯”](#ä¸å…¶ä»–æ¨¡å‹å¯¹æ¯”)
8. [å®æˆ˜åº”ç”¨](#å®æˆ˜åº”ç”¨)

---

## ğŸ¯ SmolVLA æ¦‚è¿°

### ä»€ä¹ˆæ˜¯ SmolVLAï¼Ÿ

**SmolVLA** (Small Vision-Language-Action Model) æ˜¯ Hugging Face å¼€å‘çš„è½»é‡çº§æœºå™¨äººåŸºç¡€æ¨¡å‹ï¼Œä¸“ä¸ºå®é™…æœºå™¨äººåº”ç”¨è®¾è®¡ã€‚

### æ ¸å¿ƒæ€æƒ³

```
è§†è§‰è¾“å…¥ + è¯­è¨€æŒ‡ä»¤ + æœºå™¨äººçŠ¶æ€ â†’ åŠ¨ä½œè¾“å‡º
    â†“           â†“            â†“           â†“
  æ‘„åƒå¤´       ä»»åŠ¡æè¿°     å…³èŠ‚ä½ç½®    åŠ¨ä½œå—
```

### å…³é”®ç‰¹æ€§

âœ… **å¤šæ¨¡æ€èåˆ**ï¼šè§†è§‰ + è¯­è¨€ + çŠ¶æ€
âœ… **è½»é‡é«˜æ•ˆ**ï¼š450M å‚æ•°ï¼Œå¯åœ¨æ¶ˆè´¹çº§ GPU è¿è¡Œ
âœ… **è¯­è¨€æ¡ä»¶**ï¼šè‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°
âœ… **è¿ç§»èƒ½åŠ›**ï¼šé¢„è®­ç»ƒæ¨¡å‹ï¼Œå¾®è°ƒå³ç”¨
âœ… **åŠ¨ä½œåˆ†å—**ï¼šç”ŸæˆåŠ¨ä½œåºåˆ—ï¼Œå¹³æ»‘æ‰§è¡Œ

---

## ğŸ§  æ ¸å¿ƒåŸç†

### è®¾è®¡å“²å­¦

SmolVLA å€Ÿé‰´äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„æˆåŠŸç»éªŒï¼Œå°†å…¶åº”ç”¨åˆ°æœºå™¨äººé¢†åŸŸï¼š

```
LLM: æ–‡æœ¬ â†’ æ–‡æœ¬
VLM: å›¾åƒ + æ–‡æœ¬ â†’ æ–‡æœ¬
VLA: å›¾åƒ + æ–‡æœ¬ + çŠ¶æ€ â†’ åŠ¨ä½œ
```

### ä¸‰å¤§æ ¸å¿ƒç»„ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SmolVLA                       â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   1. Vision-Language Model (VLM)     â”‚     â”‚
â”‚  â”‚      â†“                                â”‚     â”‚
â”‚  â”‚   [SmolVLM-500M]                     â”‚     â”‚
â”‚  â”‚   - è§†è§‰ç¼–ç å™¨ (SigLIP)              â”‚     â”‚
â”‚  â”‚   - è¯­è¨€æ¨¡å‹ (Transformer)           â”‚     â”‚
â”‚  â”‚   - å¤šæ¨¡æ€èåˆ                        â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                  â†“                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   2. Action Expert                   â”‚     â”‚
â”‚  â”‚      â†“                                â”‚     â”‚
â”‚  â”‚   [è½»é‡çº§ Transformer]                â”‚     â”‚
â”‚  â”‚   - çŠ¶æ€ç¼–ç                           â”‚     â”‚
â”‚  â”‚   - äº¤å‰æ³¨æ„åŠ›                        â”‚     â”‚
â”‚  â”‚   - åŠ¨ä½œè§£ç                           â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                  â†“                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   3. Action Chunking                 â”‚     â”‚
â”‚  â”‚      â†“                                â”‚     â”‚
â”‚  â”‚   [åŠ¨ä½œåºåˆ—ç”Ÿæˆ]                      â”‚     â”‚
â”‚  â”‚   - è¾“å‡º 50 æ­¥åŠ¨ä½œ                    â”‚     â”‚
â”‚  â”‚   - å¹³æ»‘æ‰§è¡Œ                          â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ æ¶æ„è¯¦è§£

### æ•´ä½“æ¶æ„å›¾

```
                        SmolVLA æ¶æ„

è¾“å…¥å±‚:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å›¾åƒè§‚æµ‹    â”‚  â”‚ è¯­è¨€æŒ‡ä»¤    â”‚  â”‚ æœºå™¨äººçŠ¶æ€  â”‚
â”‚ (å¤šè§†è§’)    â”‚  â”‚ "Pick cube" â”‚  â”‚ (å…³èŠ‚ä½ç½®)  â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚               â”‚
      â†“               â†“               â†“

ç¼–ç å±‚:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Vision-Language Model (VLM)         â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ SigLIP       â”‚      â”‚ Language    â”‚    â”‚
â”‚  â”‚ Vision       â”‚ â†’    â”‚ Transformer â”‚    â”‚
â”‚  â”‚ Encoder      â”‚      â”‚ (16 layers) â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â†“                      â†“            â”‚
â”‚    [è§†è§‰ç‰¹å¾]            [æ–‡æœ¬ç‰¹å¾]         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                    â†“                        â”‚
â”‚            [èåˆç‰¹å¾: VLM Output]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           State Projection                  â”‚
â”‚   [çŠ¶æ€] â†’ [MLP] â†’ [çŠ¶æ€åµŒå…¥]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“

Action Expert å±‚:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Action Expert Network             â”‚
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Transformer Decoder (12 layers)â”‚       â”‚
â”‚  â”‚                                  â”‚       â”‚
â”‚  â”‚  Layer 0:  Self-Attention        â”‚       â”‚
â”‚  â”‚  Layer 1:  Cross-Attention â† VLMâ”‚       â”‚
â”‚  â”‚  Layer 2:  Self-Attention        â”‚       â”‚
â”‚  â”‚  Layer 3:  Cross-Attention â† VLMâ”‚       â”‚
â”‚  â”‚  ...                             â”‚       â”‚
â”‚  â”‚  (äº¤å‰æ³¨æ„åŠ›æ¯ 2 å±‚)             â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                    â†“                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Action Head                    â”‚       â”‚
â”‚  â”‚  [éšè—å±‚] â†’ [çº¿æ€§å±‚] â†’ [åŠ¨ä½œ]    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“

è¾“å‡ºå±‚:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Action Chunk (50 steps)             â”‚
â”‚  [[aâ‚€, aâ‚, ..., aâ‚†],  â† ç¬¬ 1 æ­¥            â”‚
â”‚   [aâ‚€, aâ‚, ..., aâ‚†],  â† ç¬¬ 2 æ­¥            â”‚
â”‚   ...                                       â”‚
â”‚   [aâ‚€, aâ‚, ..., aâ‚†]]  â† ç¬¬ 50 æ­¥           â”‚
â”‚                                             â”‚
â”‚  å…¶ä¸­ aáµ¢ æ˜¯å…³èŠ‚/å¤¹çˆªçš„åŠ¨ä½œå€¼                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### è¯¦ç»†æ¨¡å—è¯´æ˜

#### 1. Vision Encoder (SigLIP)

**ä½œç”¨**ï¼šå°†å›¾åƒè½¬æ¢ä¸ºç‰¹å¾å‘é‡

```python
è¾“å…¥: å›¾åƒ (N_cameras, 3, 512, 512)
  â†“
[SigLIP Vision Transformer]
  - Patch Embedding: 512Ã—512 â†’ 32Ã—32 patches
  - Positional Encoding
  - Transformer Layers (Ã—L)
  - Layer Norm
  â†“
è¾“å‡º: è§†è§‰ç‰¹å¾ (N_cameras, N_patches, D_vision)
```

**ç‰¹ç‚¹**ï¼š
- âœ… é¢„è®­ç»ƒåœ¨å¤§è§„æ¨¡å›¾åƒ-æ–‡æœ¬å¯¹ä¸Š
- âœ… å¯¹æœºå™¨äººåœºæ™¯æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›
- âœ… æ”¯æŒå¤šè§†è§’è¾“å…¥

#### 2. Language Encoder

**ä½œç”¨**ï¼šå°†ä»»åŠ¡æè¿°ç¼–ç ä¸ºè¯­ä¹‰ç‰¹å¾

```python
è¾“å…¥: æ–‡æœ¬ "Pick the red cube and place it on the plate."
  â†“
[Tokenizer]
  - BPE åˆ†è¯
  - Token IDs
  â†“
[Language Transformer]
  - Token Embedding
  - Positional Encoding
  - Transformer Layers (Ã—16)
  â†“
è¾“å‡º: è¯­è¨€ç‰¹å¾ (N_tokens, D_language)
```

#### 3. Multimodal Fusion (VLM)

**ä½œç”¨**ï¼šèåˆè§†è§‰å’Œè¯­è¨€ä¿¡æ¯

```python
# ä¼ªä»£ç 
vision_features = vision_encoder(images)      # (B, N_patches, D)
language_features = language_encoder(text)    # (B, N_tokens, D)

# æ‹¼æ¥
combined = concat([vision_features, language_features], dim=1)
# (B, N_patches + N_tokens, D)

# Transformer å¤„ç†
for layer in vlm_layers:
    combined = layer(combined)

# è¾“å‡º
vlm_output = combined  # åŒ…å«è§†è§‰å’Œè¯­è¨€çš„èåˆè¡¨ç¤º
```

#### 4. State Projection

**ä½œç”¨**ï¼šå°†æœºå™¨äººçŠ¶æ€æ˜ å°„åˆ°æ¨¡å‹ç©ºé—´

```python
è¾“å…¥: çŠ¶æ€ (B, state_dim)  # ä¾‹å¦‚ [7] for SO101
  â†“
[Padding] â†’ (B, max_state_dim)  # è¡¥é½åˆ° 32
  â†“
[å½’ä¸€åŒ–] â†’ Mean-Std Normalization
  â†“
[MLP]
  - Linear(32, hidden_dim)
  - ReLU
  - Linear(hidden_dim, D_expert)
  â†“
è¾“å‡º: çŠ¶æ€åµŒå…¥ (B, 1, D_expert)
```

#### 5. Action Expert

**æ ¸å¿ƒ**ï¼šè¿™æ˜¯ SmolVLA çš„å…³é”®åˆ›æ–°

```python
# åˆå§‹åŒ–
queries = learnable_queries  # (1, chunk_size, D_expert)
state_emb = state_projection(state)  # (B, 1, D_expert)

# æ‹¼æ¥æŸ¥è¯¢å’ŒçŠ¶æ€
expert_input = concat([state_emb, queries], dim=1)
# (B, 1 + chunk_size, D_expert)

# Transformer Decoder
for i, layer in enumerate(expert_layers):
    # è‡ªæ³¨æ„åŠ›ï¼ˆæŸ¥è¯¢ä¹‹é—´ï¼‰
    expert_input = self_attention(expert_input)

    # æ¯ 2 å±‚ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›
    if i % 2 == 1:
        expert_input = cross_attention(
            query=expert_input,
            key_value=vlm_output  # ä» VLM è·å–ä¸Šä¸‹æ–‡
        )

    # å‰é¦ˆç½‘ç»œ
    expert_input = ffn(expert_input)

# æå–åŠ¨ä½œæŸ¥è¯¢ï¼ˆå»æ‰çŠ¶æ€ï¼‰
action_features = expert_input[:, 1:, :]  # (B, chunk_size, D_expert)

# åŠ¨ä½œå¤´
actions = action_head(action_features)  # (B, chunk_size, action_dim)
```

**è®¾è®¡è¦ç‚¹**ï¼š

1. **Learnable Queries**ï¼š
   - ç±»ä¼¼ DETR ä¸­çš„ object queries
   - æ¯ä¸ª query å¯¹åº”ä¸€ä¸ªæ—¶é—´æ­¥çš„åŠ¨ä½œ
   - é€šè¿‡è®­ç»ƒå­¦ä¹ åŠ¨ä½œåºåˆ—çš„æ—¶åºç»“æ„

2. **Cross-Attention**ï¼š
   - å…è®¸åŠ¨ä½œä¸“å®¶"æŸ¥è¯¢"è§†è§‰-è¯­è¨€ç‰¹å¾
   - åŠ¨æ€èåˆå¤šæ¨¡æ€ä¿¡æ¯
   - æ¯ 2 å±‚æ’å…¥ä¸€æ¬¡ï¼Œå¹³è¡¡è®¡ç®—å’Œæ€§èƒ½

3. **State Conditioning**ï¼š
   - å½“å‰çŠ¶æ€ä½œä¸ºç¬¬ä¸€ä¸ª token
   - ä¸ºåŠ¨ä½œç”Ÿæˆæä¾›å½“å‰ä¸Šä¸‹æ–‡

#### 6. Action Chunking

**åŠ¨æœº**ï¼šä¸€æ¬¡æ€§ç”Ÿæˆå¤šæ­¥åŠ¨ä½œï¼Œæé«˜æ‰§è¡Œå¹³æ»‘åº¦

```python
# å•æ¬¡æ¨ç†ç”Ÿæˆ 50 æ­¥åŠ¨ä½œ
actions = model.select_action(obs)  # (50, 7)

# é€æ­¥æ‰§è¡Œ
for i in range(n_action_steps):  # é€šå¸¸ n_action_steps < 50
    robot.send_action(actions[i])
    time.sleep(1 / fps)

# ä¸‹ä¸€æ¬¡æ¨ç†
obs = robot.get_observation()
actions = model.select_action(obs)  # æ›´æ–°åŠ¨ä½œå—
```

**ä¼˜åŠ¿**ï¼š
- âœ… å‡å°‘æ¨ç†é¢‘ç‡
- âœ… åŠ¨ä½œåºåˆ—æ›´å¹³æ»‘
- âœ… å‰ç»è§„åˆ’èƒ½åŠ›

---

## ğŸ“Š ä¼˜ç¼ºç‚¹åˆ†æ

### âœ… ä¼˜ç‚¹

#### 1. **è¯­è¨€æ¡ä»¶èƒ½åŠ›**

**ç¤ºä¾‹**ï¼š
```python
# ç›¸åŒç¯å¢ƒï¼Œä¸åŒä»»åŠ¡
task1 = "Pick the red cube"
task2 = "Pick the blue cube"

# æ¨¡å‹è‡ªåŠ¨ç†è§£ä»»åŠ¡å·®å¼‚
action1 = model(obs, task=task1)
action2 = model(obs, task=task2)
```

**ä»·å€¼**ï¼š
- âœ… å•ä¸ªæ¨¡å‹æ‰§è¡Œå¤šä¸ªä»»åŠ¡
- âœ… é›¶æ ·æœ¬æ³›åŒ–åˆ°æ–°ä»»åŠ¡
- âœ… äººæœºäº¤äº’å‹å¥½

#### 2. **è¿ç§»å­¦ä¹ èƒ½åŠ›**

```
é¢„è®­ç»ƒ (å¤§è§„æ¨¡æ•°æ®)
    â†“
åŸºç¡€æ¨¡å‹ (smolvla_base)
    â†“
å¾®è°ƒ (æ‚¨çš„æ•°æ® 50 episodes)
    â†“
å®šåˆ¶æ¨¡å‹
```

**å¯¹æ¯”**ï¼š
- **ä»å¤´è®­ç»ƒ**ï¼šéœ€è¦ 500+ episodes
- **ä½¿ç”¨ SmolVLA**ï¼šåªéœ€ 50 episodes âœ…

#### 3. **è½»é‡é«˜æ•ˆ**

| æ¨¡å‹ | å‚æ•°é‡ | æ˜¾å­˜ (æ¨ç†) | å»¶è¿Ÿ |
|------|--------|------------|------|
| **SmolVLA** | **450M** | **~2GB** | **~30ms** |
| RT-1 | 35M | ~1GB | ~20ms |
| RT-2 | 55B | ~100GB | ~200ms |
| OpenVLA | 7B | ~14GB | ~80ms |

**ä¼˜åŠ¿**ï¼š
- âœ… å¯åœ¨ RTX 3060 è¿è¡Œ
- âœ… é€‚åˆè¾¹ç¼˜éƒ¨ç½²
- âœ… å¿«é€Ÿæ¨ç†

#### 4. **å¤šæ¨¡æ€èåˆ**

```
è§†è§‰ (80%) + è¯­è¨€ (15%) + çŠ¶æ€ (5%)
    â†“
æ›´é²æ£’çš„å†³ç­–
```

**åœºæ™¯**ï¼š
- ğŸ“· **è§†è§‰**ï¼šç‰©ä½“åœ¨å“ªé‡Œï¼Ÿ
- ğŸ’¬ **è¯­è¨€**ï¼šè¦åšä»€ä¹ˆä»»åŠ¡ï¼Ÿ
- ğŸ¤– **çŠ¶æ€**ï¼šå½“å‰å§¿æ€å¦‚ä½•ï¼Ÿ

#### 5. **åŠ¨ä½œå¹³æ»‘**

```
ä¼ ç»Ÿæ–¹æ³•: obs â†’ action (å•æ­¥)
SmolVLA:   obs â†’ actions (50 æ­¥)
```

**å¯¹æ¯”**ï¼š
- **å•æ­¥**ï¼šåŠ¨ä½œæŠ–åŠ¨ï¼Œæ‰§è¡Œä¸ç¨³å®š
- **åŠ¨ä½œå—**ï¼šå¹³æ»‘è½¨è¿¹ï¼Œæ‰§è¡Œç¨³å®š âœ…

---

### âŒ ç¼ºç‚¹

#### 1. **è®­ç»ƒæˆæœ¬é«˜**

**èµ„æºéœ€æ±‚**ï¼š
- GPU: A100 (40GB+)
- è®­ç»ƒæ—¶é—´: ~20 å°æ—¶ (20k steps)
- æ•°æ®: 50+ episodes

**å¯¹æ¯”**ï¼š
- **ACT**: ~2 å°æ—¶ @ RTX 3090
- **Diffusion**: ~8 å°æ—¶ @ RTX 3090
- **SmolVLA**: ~20 å°æ—¶ @ A100 âŒ

#### 2. **æ•°æ®æ•æ„Ÿ**

**é—®é¢˜**ï¼šå¯¹ç¯å¢ƒå˜åŒ–æ•æ„Ÿ

```
è®­ç»ƒç¯å¢ƒ:
- æ¡Œé¢: ç™½è‰²
- å…‰ç…§: è‡ªç„¶å…‰
- æ‘„åƒå¤´: Logitech C920

æµ‹è¯•ç¯å¢ƒ:
- æ¡Œé¢: æœ¨è‰² â† æ€§èƒ½ä¸‹é™ 30%
- å…‰ç…§: è§å…‰ç¯ â† æ€§èƒ½ä¸‹é™ 20%
- æ‘„åƒå¤´: ä¸åŒå‹å· â† æ€§èƒ½ä¸‹é™ 15%
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
- åœ¨ç›®æ ‡ç¯å¢ƒé‡‡é›†æ•°æ®
- æˆ–ä½¿ç”¨åŸŸéšæœºåŒ–

#### 3. **é»‘ç›’æ€§**

**é—®é¢˜**ï¼šéš¾ä»¥è§£é‡Šå†³ç­–

```
è¾“å…¥: [å›¾åƒ, "æŠ“å–ç«‹æ–¹ä½“", çŠ¶æ€]
  â†“
[450M å‚æ•°çš„ç¥ç»ç½‘ç»œ]
  â†“
è¾“å‡º: [åŠ¨ä½œ]
```

**æŒ‘æˆ˜**ï¼š
- âŒ æ— æ³•çŸ¥é“æ¨¡å‹"çœ‹åˆ°"ä»€ä¹ˆ
- âŒ å¤±è´¥æ—¶éš¾ä»¥è°ƒè¯•
- âŒ ä¸ç¡®å®šæ€§ä¼°è®¡å›°éš¾

#### 4. **å®æ—¶æ€§é™åˆ¶**

**å»¶è¿Ÿåˆ†æ**ï¼š
```
æ¨ç†å»¶è¿Ÿ: 30ms
å›¾åƒé‡‡é›†: 33ms (30 FPS)
åŠ¨ä½œå‘é€: 5ms
æ€»è®¡: ~70ms
```

**é™åˆ¶**ï¼š
- æœ€é«˜é¢‘ç‡: ~14 Hz
- ä¸é€‚åˆé«˜é€Ÿä»»åŠ¡ï¼ˆå¦‚ä¹’ä¹“çƒï¼‰

#### 5. **è¿‡æ‹Ÿåˆé£é™©**

**ç°è±¡**ï¼š
```
è®­ç»ƒé›†: 95% æˆåŠŸç‡
éªŒè¯é›†: 80% æˆåŠŸç‡
æ–°åœºæ™¯: 50% æˆåŠŸç‡ âŒ
```

**åŸå› **ï¼š
- æ•°æ®é‡ç›¸å¯¹æ¨¡å‹å®¹é‡è¾ƒå°
- ç¼ºä¹è¶³å¤Ÿçš„å˜åŒ–
- è§†è§‰ç‰¹å¾è¿‡æ‹Ÿåˆ

---

### ğŸ†š ä¸å…¶ä»–æ¨¡å‹å¯¹æ¯”

#### SmolVLA vs ACT

| ç»´åº¦ | SmolVLA | ACT |
|------|---------|-----|
| **è¾“å…¥** | å›¾åƒ + è¯­è¨€ + çŠ¶æ€ | å›¾åƒ + çŠ¶æ€ |
| **è¯­è¨€æ¡ä»¶** | âœ… æ˜¯ | âŒ å¦ |
| **å‚æ•°é‡** | 450M | ~10M |
| **è®­ç»ƒæ—¶é—´** | ~20h | ~2h |
| **æ•°æ®éœ€æ±‚** | 50 episodes | 50 episodes |
| **è¿ç§»èƒ½åŠ›** | â­â­â­â­â­ | â­â­ |
| **é€‚ç”¨åœºæ™¯** | å¤šä»»åŠ¡ï¼Œè¯­è¨€å¼•å¯¼ | å•ä»»åŠ¡ï¼Œç²¾ç»†æ§åˆ¶ |

**é€‰æ‹©å»ºè®®**ï¼š
- **å•ä»»åŠ¡ + å¿«é€ŸåŸå‹** â†’ ACT
- **å¤šä»»åŠ¡ + è¯­è¨€äº¤äº’** â†’ SmolVLA

#### SmolVLA vs Diffusion Policy

| ç»´åº¦ | SmolVLA | Diffusion |
|------|---------|-----------|
| **ç”Ÿæˆæ–¹å¼** | è‡ªå›å½’ | æ‰©æ•£è¿‡ç¨‹ |
| **æ¨ç†é€Ÿåº¦** | ~30ms | ~50ms |
| **åŠ¨ä½œå¤šæ ·æ€§** | ä¸­ç­‰ | é«˜ |
| **è®­ç»ƒç¨³å®šæ€§** | ä¸­ç­‰ | é«˜ |
| **è¯­è¨€æ¡ä»¶** | âœ… æ˜¯ | âŒ å¦ |

**é€‰æ‹©å»ºè®®**ï¼š
- **éœ€è¦å¤šæ ·æ€§** â†’ Diffusion
- **éœ€è¦è¯­è¨€æ¡ä»¶** â†’ SmolVLA

#### SmolVLA vs OpenVLA

| ç»´åº¦ | SmolVLA | OpenVLA |
|------|---------|---------|
| **å‚æ•°é‡** | 450M | 7B |
| **è®­ç»ƒæ•°æ®** | ç¤¾åŒºæ•°æ® | 970k episodes |
| **é›¶æ ·æœ¬èƒ½åŠ›** | ä¸­ç­‰ | å¼º |
| **å¾®è°ƒæˆæœ¬** | ä½ | é«˜ |
| **ç¡¬ä»¶éœ€æ±‚** | RTX 3090 å¯ç”¨ | A100 å¿…éœ€ |

**é€‰æ‹©å»ºè®®**ï¼š
- **èµ„æºæœ‰é™** â†’ SmolVLA
- **è¿½æ±‚æ³›åŒ–** â†’ OpenVLA

---

## ğŸ› ï¸ å®ç°ç»†èŠ‚

### 1. é…ç½®å‚æ•°è¯¦è§£

```python
@dataclass
class SmolVLAConfig:
    # === è¾“å…¥/è¾“å‡º ===
    n_obs_steps: int = 1           # è§‚æµ‹å†å²æ­¥æ•°
    chunk_size: int = 50           # åŠ¨ä½œå—å¤§å°
    n_action_steps: int = 50       # å®é™…æ‰§è¡Œæ­¥æ•°

    # === å½’ä¸€åŒ– ===
    normalization_mapping: dict = {
        "VISUAL": "identity",      # å›¾åƒä¸å½’ä¸€åŒ–
        "STATE": "mean_std",       # çŠ¶æ€å½’ä¸€åŒ–
        "ACTION": "mean_std",      # åŠ¨ä½œå½’ä¸€åŒ–
    }

    # === ç»´åº¦ ===
    max_state_dim: int = 32        # çŠ¶æ€æœ€å¤§ç»´åº¦ï¼ˆè¡¥é½ï¼‰
    max_action_dim: int = 32       # åŠ¨ä½œæœ€å¤§ç»´åº¦

    # === å›¾åƒ ===
    resize_imgs_with_padding: tuple = (512, 512)

    # === VLM ===
    vlm_model_name: str = "HuggingFaceTB/SmolVLM2-500M-Video-Instruct"
    num_vlm_layers: int = 16       # VLM å±‚æ•°

    # === Action Expert ===
    num_expert_layers: int = -1    # -1 è¡¨ç¤ºä¸ VLM ç›¸åŒ
    expert_width_multiplier: float = 0.75  # Expert å®½åº¦å€æ•°
    self_attn_every_n_layers: int = 2      # äº¤å‰æ³¨æ„åŠ›é—´éš”

    # === å¾®è°ƒ ===
    freeze_vision_encoder: bool = True     # å†»ç»“è§†è§‰ç¼–ç å™¨
    train_expert_only: bool = True         # åªè®­ç»ƒ Expert
    train_state_proj: bool = True          # è®­ç»ƒçŠ¶æ€æŠ•å½±

    # === ä¼˜åŒ–å™¨ ===
    optimizer_lr: float = 1e-4
    optimizer_weight_decay: float = 1e-10
    optimizer_grad_clip_norm: float = 10

    # === è°ƒåº¦å™¨ ===
    scheduler_warmup_steps: int = 1_000
    scheduler_decay_steps: int = 30_000
```

### 2. å‰å‘ä¼ æ’­æµç¨‹

```python
def forward(self, batch: dict) -> dict:
    """
    batch = {
        "observation.images.*": (B, N_obs, 3, H, W),
        "observation.state": (B, N_obs, state_dim),
        "observation.language_tokens": (B, N_tokens),
        "action": (B, chunk_size, action_dim),
    }
    """
    B = batch["action"].shape[0]

    # 1. æå–å›¾åƒ
    images = self.extract_images(batch)  # (B * N_cameras, 3, 512, 512)

    # 2. VLM ç¼–ç 
    vlm_output = self.vlm(
        pixel_values=images,
        input_ids=batch["observation.language_tokens"],
        attention_mask=batch["observation.language_attention_mask"],
    )
    # vlm_output.last_hidden_state: (B, N_tokens_total, D_vlm)

    # 3. çŠ¶æ€æŠ•å½±
    state = batch["observation.state"][:, -1]  # å–æœ€åä¸€æ­¥
    state_emb = self.state_proj(state)  # (B, 1, D_expert)

    # 4. å‡†å¤‡ Action Expert è¾“å…¥
    queries = self.action_queries.expand(B, -1, -1)  # (B, chunk_size, D_expert)
    expert_input = torch.cat([state_emb, queries], dim=1)

    # 5. Action Expert
    for i, layer in enumerate(self.expert_layers):
        # Self-Attention
        expert_input = layer.self_attn(expert_input)

        # Cross-Attention (æ¯ 2 å±‚)
        if i % self.self_attn_every_n_layers == 1:
            expert_input = layer.cross_attn(
                query=expert_input,
                key_value=vlm_output.last_hidden_state
            )

        # FFN
        expert_input = layer.ffn(expert_input)

    # 6. æå–åŠ¨ä½œç‰¹å¾ï¼ˆå»æ‰çŠ¶æ€ï¼‰
    action_features = expert_input[:, 1:, :]  # (B, chunk_size, D_expert)

    # 7. åŠ¨ä½œå¤´
    pred_actions = self.action_head(action_features)  # (B, chunk_size, action_dim)

    # 8. è®¡ç®—æŸå¤±
    loss = F.mse_loss(pred_actions, batch["action"])

    return {
        "loss": loss,
        "action": pred_actions,
    }
```

### 3. æ¨ç†æµç¨‹

```python
@torch.no_grad()
def select_action(self, observation: dict) -> torch.Tensor:
    """
    observation = {
        "observation.images.front": (3, H, W),
        "observation.state": (state_dim,),
        "task": "Pick the red cube",
    }
    """
    self.eval()

    # 1. å‡†å¤‡æ‰¹æ¬¡
    batch = self.prepare_batch(observation)

    # 2. å‰å‘ä¼ æ’­
    output = self.forward(batch)

    # 3. æå–åŠ¨ä½œ
    actions = output["action"][0]  # (chunk_size, action_dim)

    # 4. åå½’ä¸€åŒ–
    actions = self.unnormalize_action(actions)

    return actions  # (chunk_size, action_dim)
```

---

## ğŸ“ è®­ç»ƒç­–ç•¥

### é¢„è®­ç»ƒ vs ä»å¤´è®­ç»ƒ

#### æ–¹æ¡ˆ 1ï¼šä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ¨èï¼‰

```bash
lerobot-train \
  --policy.path=lerobot/smolvla_base \  # åŠ è½½é¢„è®­ç»ƒ
  --dataset.repo_id=your_user/your_dataset \
  --batch_size=64 \
  --steps=20000
```

**ä¼˜åŠ¿**ï¼š
- âœ… åªéœ€ 50 episodes
- âœ… è®­ç»ƒæ›´å¿«ï¼ˆ20k steps vs 100k+ï¼‰
- âœ… æ€§èƒ½æ›´å¥½ï¼ˆé¢„è®­ç»ƒçŸ¥è¯†ï¼‰

#### æ–¹æ¡ˆ 2ï¼šä»å¤´è®­ç»ƒ

```bash
lerobot-train \
  --policy.type=smolvla \  # ä»å¤´åˆå§‹åŒ–
  --policy.load_vlm_weights=true \  # åŠ è½½ VLM æƒé‡
  --dataset.repo_id=your_user/your_dataset \
  --batch_size=64 \
  --steps=100000  # éœ€è¦æ›´å¤šæ­¥æ•°
```

**åŠ£åŠ¿**ï¼š
- âŒ éœ€è¦ 500+ episodes
- âŒ è®­ç»ƒæ—¶é—´é•¿
- âŒ å¯èƒ½ä¸æ”¶æ•›

### å¾®è°ƒç­–ç•¥

#### ç­–ç•¥ 1ï¼šå†»ç»“ VLMï¼Œåªè®­ç»ƒ Expertï¼ˆé»˜è®¤ï¼‰

```python
config.freeze_vision_encoder = True
config.train_expert_only = True
config.train_state_proj = True
```

**é€‚ç”¨**ï¼š
- æ•°æ®é‡å°ï¼ˆ50 episodesï¼‰
- ä»»åŠ¡ä¸é¢„è®­ç»ƒç±»ä¼¼
- èµ„æºæœ‰é™

#### ç­–ç•¥ 2ï¼šç«¯åˆ°ç«¯å¾®è°ƒ

```python
config.freeze_vision_encoder = False
config.train_expert_only = False
```

**é€‚ç”¨**ï¼š
- æ•°æ®é‡å¤§ï¼ˆ100+ episodesï¼‰
- ä»»åŠ¡å·®å¼‚å¤§
- è¿½æ±‚æœ€ä½³æ€§èƒ½

### è¶…å‚æ•°è°ƒä¼˜

| å‚æ•° | é»˜è®¤ | å°æ•°æ® | å¤§æ•°æ® |
|------|------|--------|--------|
| **Learning Rate** | 1e-4 | 5e-5 | 2e-4 |
| **Batch Size** | 64 | 32 | 128 |
| **Steps** | 20k | 15k | 40k |
| **Warmup** | 1k | 500 | 2k |

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### å®˜æ–¹åŸºå‡†ï¼ˆSO101 Pick-Placeï¼‰

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| **æ•°æ®é›†** | 50 episodes |
| **è®­ç»ƒæ—¶é—´** | 4 hours @ A100 |
| **æˆåŠŸç‡ (è®­ç»ƒç¯å¢ƒ)** | 85% |
| **æˆåŠŸç‡ (æ–°ä½ç½®)** | 72% |
| **æ¨ç†å»¶è¿Ÿ** | 30ms |

### æ¶ˆèå®éªŒ

| é…ç½® | æˆåŠŸç‡ |
|------|--------|
| **Full SmolVLA** | **85%** |
| - æ— è¯­è¨€æ¡ä»¶ | 78% |
| - æ— åŠ¨ä½œåˆ†å— | 71% |
| - æ— é¢„è®­ç»ƒ | 65% |
| - å•è§†è§’ | 73% |

**ç»“è®º**ï¼š
- è¯­è¨€æ¡ä»¶è´¡çŒ® 7%
- åŠ¨ä½œåˆ†å—è´¡çŒ® 14%
- é¢„è®­ç»ƒè´¡çŒ® 20%
- å¤šè§†è§’è´¡çŒ® 12%

---

## ğŸ’¡ å®æˆ˜æŠ€å·§

### 1. æ•°æ®é‡‡é›†

**æœ€ä½³å®è·µ**ï¼š
```python
# å¤šæ ·åŒ–ç‰©ä½“ä½ç½®
positions = [
    (x, y) for x in [-0.1, 0, 0.1]
              for y in [-0.1, 0, 0.1]
]  # 9 ä¸ªä½ç½®

# æ¯ä¸ªä½ç½® 6 ä¸ªæ¼”ç¤º
for pos in positions:
    for _ in range(6):
        record_episode(object_position=pos)

# æ€»è®¡: 9 Ã— 6 = 54 episodes
```

### 2. ä»»åŠ¡æè¿°

**å¥½çš„æè¿°**ï¼š
```
âœ… "Pick the red cube and place it on the blue plate."
âœ… "Grasp the mug handle and lift it up."
âœ… "Push the button on the left side."
```

**åçš„æè¿°**ï¼š
```
âŒ "Do the task."  # å¤ªæ¨¡ç³Š
âŒ "Move robot."   # æ— å…·ä½“ä¿¡æ¯
âŒ "æŠ“å–ç«‹æ–¹ä½“"    # ä½¿ç”¨ä¸­æ–‡ï¼ˆæ¨¡å‹æ˜¯è‹±æ–‡è®­ç»ƒï¼‰
```

### 3. æ‘„åƒå¤´è®¾ç½®

**æ¨èé…ç½®**ï¼š
```python
cameras = {
    "front": {  # ç¬¬ä¸‰äººç§°è§†è§’
        "position": "45åº¦ä¿¯è§†ï¼Œè·ç¦» 1m",
        "resolution": (640, 480),
        "fov": "èƒ½çœ‹åˆ°æ•´ä¸ªå·¥ä½œåŒº",
    },
    "wrist": {  # ç¬¬ä¸€äººç§°è§†è§’ï¼ˆå¯é€‰ï¼‰
        "position": "å®‰è£…åœ¨è…•éƒ¨",
        "resolution": (640, 480),
        "fov": "è¦†ç›–å¤¹çˆªå’Œç›®æ ‡ç‰©ä½“",
    }
}
```

### 4. è°ƒè¯•æŠ€å·§

```python
# å¯è§†åŒ–æ³¨æ„åŠ›
def visualize_attention(model, obs):
    # è·å–äº¤å‰æ³¨æ„åŠ›æƒé‡
    attn_weights = model.get_attention_weights(obs)

    # å¯è§†åŒ–å“ªäº›è§†è§‰ patch è¢«å…³æ³¨
    import matplotlib.pyplot as plt
    plt.imshow(attn_weights)
    plt.show()

# æ£€æŸ¥åŠ¨ä½œåˆ†å¸ƒ
def check_action_stats(dataset):
    actions = dataset.meta.stats["action"]
    print(f"Mean: {actions['mean']}")
    print(f"Std: {actions['std']}")
    print(f"Min: {actions['min']}")
    print(f"Max: {actions['max']}")
```

---

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹ç¤ºä¾‹

### å®Œæ•´æµç¨‹ï¼ˆ5 æ­¥ï¼‰

```python
# === æ­¥éª¤ 1: åŠ è½½æ¨¡å‹ ===
from lerobot.policies.smolvla import SmolVLAPolicy

policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
policy.eval()
policy.to("cuda")

# === æ­¥éª¤ 2: å‡†å¤‡è§‚æµ‹ ===
import numpy as np
from PIL import Image

obs = {
    "observation.images.front": np.array(Image.open("front.jpg")),
    "observation.state": np.array([0.1, 0.2, 0.3, 0.0, 0.0, 0.0, 0.0]),
}

# === æ­¥éª¤ 3: è®¾ç½®ä»»åŠ¡ ===
task = "Pick the red cube and place it on the plate."

# === æ­¥éª¤ 4: ç”ŸæˆåŠ¨ä½œ ===
actions = policy.select_action(obs, task=task)
print(actions.shape)  # (50, 7)

# === æ­¥éª¤ 5: æ‰§è¡Œ ===
for i in range(50):
    robot.send_action(actions[i])
    time.sleep(0.033)  # 30 Hz
```

---

## ğŸ“š å­¦ä¹ èµ„æº

### è®ºæ–‡å’Œåšå®¢

- **SmolVLA è®ºæ–‡**: https://huggingface.co/papers/2506.01844
- **SmolVLA åšå®¢**: https://huggingface.co/blog/smolvla
- **SmolVLM è®ºæ–‡**: SmolVLM2 æŠ€æœ¯æŠ¥å‘Š

### ä»£ç å’Œæ¨¡å‹

- **é¢„è®­ç»ƒæ¨¡å‹**: https://huggingface.co/lerobot/smolvla_base
- **ç¤ºä¾‹æ•°æ®é›†**: https://huggingface.co/datasets/lerobot/svla_so101_pickplace
- **æºä»£ç **: https://github.com/huggingface/lerobot

---

## ğŸ”® æœªæ¥æ–¹å‘

SmolVLA çš„å‘å±•æ–¹å‘ï¼š

1. **æ›´å¤§çš„é¢„è®­ç»ƒæ•°æ®**ï¼šæå‡é›¶æ ·æœ¬èƒ½åŠ›
2. **å¤šæ¨¡æ€è¾“å…¥**ï¼šè§¦è§‰ã€åŠ›åé¦ˆç­‰
3. **åœ¨çº¿å­¦ä¹ **ï¼šè¾¹éƒ¨ç½²è¾¹æ”¹è¿›
4. **æ¨¡å‹å‹ç¼©**ï¼šé‡åŒ–ã€å‰ªæï¼Œéƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡
5. **å±‚æ¬¡åŒ–å†³ç­–**ï¼šé•¿æœŸè§„åˆ’ + çŸ­æœŸæ§åˆ¶

---

## âœ… æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **SmolVLA = VLM + Action Expert + Action Chunking**
2. **ä¼˜åŠ¿**ï¼šè¯­è¨€æ¡ä»¶ã€è¿ç§»å­¦ä¹ ã€è½»é‡é«˜æ•ˆ
3. **åŠ£åŠ¿**ï¼šè®­ç»ƒæˆæœ¬ã€æ•°æ®æ•æ„Ÿã€é»‘ç›’æ€§
4. **é€‚ç”¨**ï¼šå¤šä»»åŠ¡ã€è¯­è¨€å¼•å¯¼ã€èµ„æºæœ‰é™çš„åœºæ™¯

### ä½•æ—¶ä½¿ç”¨ SmolVLAï¼Ÿ

âœ… **é€‚åˆ**ï¼š
- å¤šä»»åŠ¡åœºæ™¯
- éœ€è¦è¯­è¨€äº¤äº’
- æœ‰ 50+ é«˜è´¨é‡æ•°æ®
- æœ‰ GPUï¼ˆRTX 3090+ï¼‰

âŒ **ä¸é€‚åˆ**ï¼š
- å•ä»»åŠ¡ã€æ— è¯­è¨€éœ€æ±‚ â†’ ç”¨ ACT
- éœ€è¦é«˜åº¦å¤šæ ·æ€§ â†’ ç”¨ Diffusion
- æ•°æ®é‡æå°‘ï¼ˆ< 25ï¼‰ â†’ æ”¶é›†æ›´å¤šæ•°æ®

---

**SmolVLA ä»£è¡¨äº†æœºå™¨äººå­¦ä¹ çš„ä¸€ä¸ªé‡è¦æ–¹å‘ï¼šå°†å¤§æ¨¡å‹çš„æˆåŠŸç»éªŒè¿ç§»åˆ°æœºå™¨äººé¢†åŸŸï¼Œé€šè¿‡è¯­è¨€å®ç°æ›´è‡ªç„¶çš„äººæœºäº¤äº’ã€‚è™½ç„¶ä»æœ‰æŒ‘æˆ˜ï¼Œä½†å…¶è½»é‡é«˜æ•ˆçš„ç‰¹æ€§ä½¿å…¶æˆä¸ºå®é™…åº”ç”¨çš„æœ‰åŠ›å·¥å…·ã€‚**