#!/usr/bin/env python3
"""
SmolVLA æ¨¡å‹è®­ç»ƒè„šæœ¬ (MuJoCo æ•°æ®)

è¿™ä¸ªè„šæœ¬ä½¿ç”¨ä» MuJoCo ç¯å¢ƒé‡‡é›†çš„æ•°æ®è®­ç»ƒ SmolVLA æ¨¡å‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    python 02_train_smolvla.py --dataset_repo_id your_username/mujoco_so101_pickplace

æ³¨æ„:
    - éœ€è¦ GPU (æ¨è A100 æˆ– RTX 3090+)
    - è®­ç»ƒæ—¶é—´çº¦ 4-8 å°æ—¶
    - ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ä¿å­˜ checkpoints
"""

import argparse
import logging
from pathlib import Path
import subprocess
import sys

import torch

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_gpu():
    """æ£€æŸ¥ GPU å¯ç”¨æ€§"""
    if not torch.cuda.is_available():
        logger.warning("âš ï¸ æœªæ£€æµ‹åˆ° CUDA GPU!")
        logger.warning("è®­ç»ƒå°†éå¸¸æ…¢ã€‚æ¨èä½¿ç”¨:")
        logger.warning("  - Google Colab (å…è´¹ GPU)")
        logger.warning("  - AWS/GCP äº‘ GPU")
        logger.warning("  - æœ¬åœ° NVIDIA GPU")
        response = input("\næ˜¯å¦ç»§ç»­ä½¿ç”¨ CPU è®­ç»ƒ? (y/n): ")
        if response.lower() != 'y':
            sys.exit(0)
        return False
    else:
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        logger.info(f"âœ“ æ£€æµ‹åˆ° GPU: {gpu_name}")
        logger.info(f"âœ“ GPU æ˜¾å­˜: {gpu_memory:.1f} GB")
        return True


def print_training_info(args):
    """æ‰“å°è®­ç»ƒä¿¡æ¯"""
    print("=" * 70)
    print("ğŸš€ SmolVLA æ¨¡å‹è®­ç»ƒ")
    print("=" * 70)
    print()
    print("ğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"  æ•°æ®é›†: {args.dataset_repo_id}")
    print(f"  æ¨¡å‹: {args.policy_path}")
    print(f"  Batch Size: {args.batch_size}")
    print(f"  è®­ç»ƒæ­¥æ•°: {args.steps}")
    print(f"  å­¦ä¹ ç‡: {args.learning_rate}")
    print(f"  è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"  ä½¿ç”¨ W&B: {args.use_wandb}")
    print()
    print("ğŸ“ˆ é¢„è®¡è®­ç»ƒæ—¶é—´:")
    print(f"  A100 GPU: ~4 å°æ—¶")
    print(f"  RTX 3090: ~6-8 å°æ—¶")
    print(f"  CPU: ä¸æ¨è (å¤ªæ…¢)")
    print()
    print("ğŸ’¡ æç¤º:")
    print("  - è®­ç»ƒä¼šè‡ªåŠ¨ä¿å­˜ checkpoints")
    print("  - å¯ä»¥ä½¿ç”¨ Ctrl+C å®‰å…¨ä¸­æ–­")
    print("  - ä½¿ç”¨ W&B å¯ä»¥å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦")
    print()
    print("=" * 70)
    print()


def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒ SmolVLA æ¨¡å‹")

    # æ•°æ®é›†é…ç½®
    parser.add_argument(
        "--dataset_repo_id",
        type=str,
        required=True,
        help="Hugging Face æ•°æ®é›† repo_id (ä¾‹å¦‚: username/dataset_name)"
    )

    # æ¨¡å‹é…ç½®
    parser.add_argument(
        "--policy_path",
        type=str,
        default="lerobot/smolvla_base",
        help="é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„"
    )

    # è®­ç»ƒå‚æ•°
    parser.add_argument(
        "--batch_size",
        type=int,
        default=64,
        help="æ‰¹æ¬¡å¤§å° (A100: 64, RTX 3090: 32-48)"
    )
    parser.add_argument(
        "--steps",
        type=int,
        default=20000,
        help="è®­ç»ƒæ­¥æ•°"
    )
    parser.add_argument(
        "--learning_rate",
        type=float,
        default=1e-4,
        help="å­¦ä¹ ç‡"
    )
    parser.add_argument(
        "--eval_freq",
        type=int,
        default=1000,
        help="è¯„ä¼°é¢‘ç‡ (æ¯ N æ­¥)"
    )
    parser.add_argument(
        "--save_freq",
        type=int,
        default=2000,
        help="ä¿å­˜ checkpoint é¢‘ç‡ (æ¯ N æ­¥)"
    )

    # è¾“å‡ºé…ç½®
    parser.add_argument(
        "--output_dir",
        type=str,
        default="outputs/mujoco_smolvla",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--job_name",
        type=str,
        default="smolvla_mujoco_so101",
        help="ä»»åŠ¡åç§°"
    )

    # W&B é…ç½®
    parser.add_argument(
        "--use_wandb",
        action="store_true",
        help="ä½¿ç”¨ Weights & Biases è®°å½•è®­ç»ƒ"
    )
    parser.add_argument(
        "--wandb_project",
        type=str,
        default="lerobot-mujoco",
        help="W&B é¡¹ç›®åç§°"
    )
    parser.add_argument(
        "--wandb_run_name",
        type=str,
        default=None,
        help="W&B run åç§°"
    )

    # å…¶ä»–
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        choices=["cuda", "cpu"],
        help="è®­ç»ƒè®¾å¤‡"
    )
    parser.add_argument(
        "--num_workers",
        type=int,
        default=4,
        help="æ•°æ®åŠ è½½å™¨çš„å·¥ä½œè¿›ç¨‹æ•°"
    )

    args = parser.parse_args()

    # æ£€æŸ¥ GPU
    has_gpu = check_gpu()
    if args.device == "cuda" and not has_gpu:
        args.device = "cpu"
        args.batch_size = min(args.batch_size, 8)  # CPU æ—¶å‡å° batch size

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # è®¾ç½® W&B run name
    if args.wandb_run_name is None:
        args.wandb_run_name = args.job_name

    # æ‰“å°è®­ç»ƒä¿¡æ¯
    print_training_info(args)

    # ç¡®è®¤å¼€å§‹
    response = input("æ˜¯å¦å¼€å§‹è®­ç»ƒ? (y/n): ")
    if response.lower() != 'y':
        logger.info("è®­ç»ƒå–æ¶ˆ")
        return

    # æ„å»ºè®­ç»ƒå‘½ä»¤
    # æ³¨æ„: lerobot å¯èƒ½æ²¡æœ‰æ ‡å‡†çš„ train å‘½ä»¤ï¼Œè¿™é‡Œæä¾›ç¤ºä¾‹
    # å®é™…ä½¿ç”¨æ—¶éœ€è¦æ ¹æ® lerobot çš„ API è°ƒæ•´

    logger.info("\nğŸš€ å¼€å§‹è®­ç»ƒ...\n")

    try:
        # æ–¹æ³• 1: ä½¿ç”¨ lerobot çš„è®­ç»ƒè„šæœ¬ (å¦‚æœå­˜åœ¨)
        # è¿™é‡Œæˆ‘ä»¬æä¾›ä¸€ä¸ªé€šç”¨çš„è®­ç»ƒæµç¨‹

        from lerobot.datasets.lerobot_dataset import LeRobotDataset
        from lerobot.policies.smolvla import SmolVLAPolicy

        logger.info("åŠ è½½æ•°æ®é›†...")
        dataset = LeRobotDataset(
            repo_id=args.dataset_repo_id,
            root=None,  # è‡ªåŠ¨ä¸‹è½½åˆ°ç¼“å­˜
            download_videos=True
        )
        logger.info(f"âœ“ æ•°æ®é›†åŠ è½½æˆåŠŸ: {dataset.num_episodes} episodes, {dataset.num_frames} frames")

        logger.info("\nåŠ è½½æ¨¡å‹...")
        device = torch.device(args.device)

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        policy = SmolVLAPolicy.from_pretrained(args.policy_path)
        policy = policy.to(device)
        logger.info(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        logger.info(f"  å‚æ•°é‡: {sum(p.numel() for p in policy.parameters()) / 1e6:.1f}M")

        # åˆ›å»ºè®­ç»ƒå™¨
        logger.info("\nåˆå§‹åŒ–è®­ç»ƒ...")

        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„ SmolVLA è®­ç»ƒ API è¿›è¡Œè°ƒæ•´
        # ä»¥ä¸‹æ˜¯ç¤ºä¾‹ä»£ç 

        logger.info("\n" + "=" * 70)
        logger.info("âš ï¸ æ³¨æ„: å®Œæ•´çš„è®­ç»ƒå¾ªç¯éœ€è¦æ ¹æ® SmolVLA çš„ API å®ç°")
        logger.info("å»ºè®®ä½¿ç”¨ lerobot æä¾›çš„å®˜æ–¹è®­ç»ƒè„šæœ¬")
        logger.info("=" * 70)
        logger.info("\næ¨èå‘½ä»¤:")

        cmd_parts = [
            "python", "-m", "lerobot.scripts.train",
            f"--policy.path={args.policy_path}",
            f"--dataset.repo_id={args.dataset_repo_id}",
            f"--batch_size={args.batch_size}",
            f"--steps={args.steps}",
            f"--lr={args.learning_rate}",
            f"--output_dir={args.output_dir}",
            f"--job_name={args.job_name}",
            f"--device={args.device}",
        ]

        if args.use_wandb:
            cmd_parts.extend([
                f"--wandb.enable=true",
                f"--wandb.project={args.wandb_project}",
                f"--wandb.run_name={args.wandb_run_name}",
            ])

        print("\n" + " ".join(cmd_parts) + "\n")

        logger.info("\nğŸ’¡ å¦‚æœä¸Šè¿°å‘½ä»¤ä¸é€‚ç”¨ï¼Œè¯·å‚è€ƒ LeRobot æ–‡æ¡£:")
        logger.info("https://huggingface.co/docs/lerobot")

    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        logger.error("\nè¯·æ£€æŸ¥:")
        logger.error("  1. æ•°æ®é›† repo_id æ˜¯å¦æ­£ç¡®")
        logger.error("  2. SmolVLA æ¨¡å‹æ˜¯å¦å·²å®‰è£…: pip install -e '.[smolvla]'")
        logger.error("  3. GPU æ˜¾å­˜æ˜¯å¦è¶³å¤Ÿ")
        raise


if __name__ == "__main__":
    main()
