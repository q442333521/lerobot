{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmolVLA æ¨¡å‹è®­ç»ƒ (MuJoCo æ•°æ®)\n",
    "\n",
    "è¿™ä¸ª Notebook ä½¿ç”¨ä» MuJoCo ç¯å¢ƒé‡‡é›†çš„æ•°æ®è®­ç»ƒ SmolVLA æ¨¡å‹ã€‚\n",
    "\n",
    "## âš ï¸ æ³¨æ„äº‹é¡¹\n",
    "\n",
    "- **éœ€è¦ GPU**: æ¨è A100 æˆ– RTX 3090+\n",
    "- **è®­ç»ƒæ—¶é—´**: çº¦ 4-8 å°æ—¶ï¼ˆå–å†³äº GPUï¼‰\n",
    "- **ç£ç›˜ç©ºé—´**: ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´ä¿å­˜ checkpoints (çº¦ 10-20GB)\n",
    "- **Sim2Real Gap**: MuJoCo è®­ç»ƒçš„æ¨¡å‹ä¸èƒ½ç›´æ¥ç”¨äºçœŸå®æœºæ¢°è‡‚\n",
    "\n",
    "## ğŸ“ˆ é¢„è®¡è®­ç»ƒæ—¶é—´\n",
    "\n",
    "- A100 GPU: ~4 å°æ—¶\n",
    "- RTX 3090: ~6-8 å°æ—¶  \n",
    "- RTX 3080: ~8-10 å°æ—¶\n",
    "- CPU: ä¸æ¨èï¼ˆå¤ªæ…¢ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“¦ æ­¥éª¤ 0: å¯¼å…¥åº“å’Œç¯å¢ƒæ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… åº“å¯¼å…¥æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ’» æ­¥éª¤ 1: æ£€æŸ¥ GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” æ£€æŸ¥ GPU...\\n\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"âš ï¸ æœªæ£€æµ‹åˆ° CUDA GPU!\")\n",
    "    print(\"è®­ç»ƒå°†éå¸¸æ…¢ã€‚æ¨èä½¿ç”¨:\")\n",
    "    print(\"  - Google Colab (å…è´¹ GPU)\")\n",
    "    print(\"  - AWS/GCP äº‘ GPU\")\n",
    "    print(\"  - æœ¬åœ° NVIDIA GPU\")\n",
    "    print()\n",
    "    \n",
    "    # è¯¢é—®æ˜¯å¦ç»§ç»­\n",
    "    response = input(\"æ˜¯å¦ç»§ç»­ä½¿ç”¨ CPU è®­ç»ƒ? (y/n): \")\n",
    "    if response.lower() != 'y':\n",
    "        raise RuntimeError(\"éœ€è¦ GPU è¿›è¡Œè®­ç»ƒ\")\n",
    "    has_gpu = False\n",
    "else:\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"âœ“ æ£€æµ‹åˆ° GPU: {gpu_name}\")\n",
    "    print(f\"âœ“ GPU æ˜¾å­˜: {gpu_memory:.1f} GB\")\n",
    "    has_gpu = True\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âš™ï¸ æ­¥éª¤ 2: é…ç½®è®­ç»ƒå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== æ•°æ®é›†é…ç½® ==========\n",
    "DATASET_REPO_ID = \"your_username/mujoco_so101_pickplace\"  # ä¿®æ”¹ä¸ºæ‚¨çš„æ•°æ®é›†\n",
    "\n",
    "# ========== æ¨¡å‹é…ç½® ==========\n",
    "POLICY_PATH = \"lerobot/smolvla_base\"  # é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„\n",
    "\n",
    "# ========== è®­ç»ƒå‚æ•° ==========\n",
    "BATCH_SIZE = 64  # A100: 64, RTX 3090: 32-48, RTX 3080: 24-32\n",
    "STEPS = 20000  # è®­ç»ƒæ­¥æ•°\n",
    "LEARNING_RATE = 1e-4  # å­¦ä¹ ç‡\n",
    "EVAL_FREQ = 1000  # è¯„ä¼°é¢‘ç‡ï¼ˆæ¯ N æ­¥ï¼‰\n",
    "SAVE_FREQ = 2000  # ä¿å­˜ checkpoint é¢‘ç‡ï¼ˆæ¯ N æ­¥ï¼‰\n",
    "\n",
    "# ========== è¾“å‡ºé…ç½® ==========\n",
    "OUTPUT_DIR = \"outputs/mujoco_smolvla\"  # è¾“å‡ºç›®å½•\n",
    "JOB_NAME = \"smolvla_mujoco_so101\"  # ä»»åŠ¡åç§°\n",
    "\n",
    "# ========== W&B é…ç½® ==========\n",
    "USE_WANDB = True  # ä½¿ç”¨ Weights & Biases è®°å½•è®­ç»ƒ\n",
    "WANDB_PROJECT = \"lerobot-mujoco\"  # W&B é¡¹ç›®åç§°\n",
    "WANDB_RUN_NAME = JOB_NAME  # W&B run åç§°\n",
    "\n",
    "# ========== è®¾å¤‡é…ç½® ==========\n",
    "DEVICE = \"cuda\" if has_gpu else \"cpu\"\n",
    "NUM_WORKERS = 4  # æ•°æ®åŠ è½½å™¨çš„å·¥ä½œè¿›ç¨‹æ•°\n",
    "\n",
    "# å¦‚æœä½¿ç”¨ CPUï¼Œå‡å° batch size\n",
    "if DEVICE == \"cpu\":\n",
    "    BATCH_SIZE = min(BATCH_SIZE, 8)\n",
    "\n",
    "# åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… è®­ç»ƒé…ç½®:\")\n",
    "print(f\"  æ•°æ®é›†: {DATASET_REPO_ID}\")\n",
    "print(f\"  æ¨¡å‹: {POLICY_PATH}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  è®­ç»ƒæ­¥æ•°: {STEPS}\")\n",
    "print(f\"  å­¦ä¹ ç‡: {LEARNING_RATE}\")\n",
    "print(f\"  è¾“å‡ºç›®å½•: {OUTPUT_DIR}\")\n",
    "print(f\"  ä½¿ç”¨ W&B: {USE_WANDB}\")\n",
    "print(f\"  è®¾å¤‡: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ” æ­¥éª¤ 3: ç™»å½• Hugging Face å’Œ W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç™»å½• Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "print(\"ğŸ” ç™»å½• Hugging Face...\")\n",
    "notebook_login()\n",
    "print(\"âœ… HF ç™»å½•æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç™»å½• Weights & Biases (å¯é€‰)\n",
    "if USE_WANDB:\n",
    "    import wandb\n",
    "    print(\"ğŸ” ç™»å½• Weights & Biases...\")\n",
    "    wandb.login()\n",
    "    print(\"âœ… W&B ç™»å½•æˆåŠŸï¼\")\n",
    "else:\n",
    "    print(\"âš ï¸ W&B æœªå¯ç”¨ï¼Œè·³è¿‡ç™»å½•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“‚ æ­¥éª¤ 4: åŠ è½½æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "print(\"ğŸ“‚ åŠ è½½æ•°æ®é›†...\")\n",
    "\n",
    "dataset = LeRobotDataset(\n",
    "    repo_id=DATASET_REPO_ID,\n",
    "    root=None,  # è‡ªåŠ¨ä¸‹è½½åˆ°ç¼“å­˜\n",
    "    download_videos=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ\")\n",
    "print(f\"  Episodes: {dataset.num_episodes}\")\n",
    "print(f\"  Frames: {dataset.num_frames}\")\n",
    "print(f\"  FPS: {dataset.fps}\")\n",
    "print(f\"  ç‰¹å¾: {list(dataset.features.keys())}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ§  æ­¥éª¤ 5: åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.policies.smolvla import SmolVLAPolicy\n",
    "\n",
    "print(\"ğŸ§  åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...\")\n",
    "\n",
    "device = torch.device(DEVICE)\n",
    "\n",
    "# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹\n",
    "policy = SmolVLAPolicy.from_pretrained(POLICY_PATH)\n",
    "policy = policy.to(device)\n",
    "\n",
    "param_count = sum(p.numel() for p in policy.parameters()) / 1e6\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\")\n",
    "print(f\"  å‚æ•°é‡: {param_count:.1f}M\")\n",
    "print(f\"  è®¾å¤‡: {device}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š æ­¥éª¤ 6: è®­ç»ƒè¯´æ˜\n",
    "\n",
    "### å…³äºè®­ç»ƒ\n",
    "\n",
    "ç”±äºå®Œæ•´çš„è®­ç»ƒå¾ªç¯éœ€è¦æ ¹æ® LeRobot çš„å…·ä½“ API å®ç°ï¼Œè¿™é‡Œæä¾›ä¸¤ç§è®­ç»ƒæ–¹å¼ï¼š\n",
    "\n",
    "#### æ–¹æ³• A: ä½¿ç”¨ LeRobot å‘½ä»¤è¡Œå·¥å…· (æ¨è)\n",
    "\n",
    "åœ¨ç»ˆç«¯è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n",
    "\n",
    "```bash\n",
    "python -m lerobot.scripts.train \\\n",
    "  --policy.path=lerobot/smolvla_base \\\n",
    "  --dataset.repo_id=your_username/mujoco_so101_pickplace \\\n",
    "  --batch_size=64 \\\n",
    "  --steps=20000 \\\n",
    "  --lr=1e-4 \\\n",
    "  --output_dir=outputs/mujoco_smolvla \\\n",
    "  --job_name=smolvla_mujoco_so101 \\\n",
    "  --device=cuda \\\n",
    "  --wandb.enable=true \\\n",
    "  --wandb.project=lerobot-mujoco \\\n",
    "  --wandb.run_name=smolvla_mujoco_so101\n",
    "```\n",
    "\n",
    "#### æ–¹æ³• B: åœ¨ Notebook ä¸­è®­ç»ƒ\n",
    "\n",
    "è¿è¡Œä¸‹ä¸€ä¸ªå•å…ƒæ ¼ç”Ÿæˆè®­ç»ƒå‘½ä»¤ï¼Œç„¶ååœ¨ç»ˆç«¯æ‰§è¡Œã€‚\n",
    "\n",
    "### è®­ç»ƒç›‘æ§\n",
    "\n",
    "å¦‚æœå¯ç”¨äº† W&Bï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ç›‘æ§è®­ç»ƒï¼š\n",
    "\n",
    "```\n",
    "https://wandb.ai/your_username/lerobot-mujoco\n",
    "```\n",
    "\n",
    "åœ¨ Dashboard ä¸­å¯ä»¥æŸ¥çœ‹ï¼š\n",
    "- Loss æ›²çº¿\n",
    "- Learning rate\n",
    "- GPU ä½¿ç”¨ç‡\n",
    "- è®­ç»ƒé€Ÿåº¦ (steps/sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸš€ æ­¥éª¤ 7: ç”Ÿæˆè®­ç»ƒå‘½ä»¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆè®­ç»ƒå‘½ä»¤\n",
    "cmd_parts = [\n",
    "    \"python\", \"-m\", \"lerobot.scripts.train\",\n",
    "    f\"--policy.path={POLICY_PATH}\",\n",
    "    f\"--dataset.repo_id={DATASET_REPO_ID}\",\n",
    "    f\"--batch_size={BATCH_SIZE}\",\n",
    "    f\"--steps={STEPS}\",\n",
    "    f\"--lr={LEARNING_RATE}\",\n",
    "    f\"--output_dir={OUTPUT_DIR}\",\n",
    "    f\"--job_name={JOB_NAME}\",\n",
    "    f\"--device={DEVICE}\",\n",
    "]\n",
    "\n",
    "if USE_WANDB:\n",
    "    cmd_parts.extend([\n",
    "        f\"--wandb.enable=true\",\n",
    "        f\"--wandb.project={WANDB_PROJECT}\",\n",
    "        f\"--wandb.run_name={WANDB_RUN_NAME}\",\n",
    "    ])\n",
    "\n",
    "train_command = \" \".join(cmd_parts)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸš€ è®­ç»ƒå‘½ä»¤\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(train_command)\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"ğŸ’¡ è¯·åœ¨ç»ˆç«¯è¿è¡Œä¸Šè¿°å‘½ä»¤\")\n",
    "print()\n",
    "print(\"å¦‚æœå‘½ä»¤ä¸é€‚ç”¨ï¼Œè¯·å‚è€ƒ LeRobot æ–‡æ¡£:\")\n",
    "print(\"https://huggingface.co/docs/lerobot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ˆ æ­¥éª¤ 8: è®­ç»ƒè¿›åº¦ç›‘æ§ï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "å¦‚æœæ‚¨åœ¨ç»ˆç«¯è¿è¡Œè®­ç»ƒï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ç›‘æ§è¿›åº¦ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹æœ€æ–°çš„ checkpoint\n",
    "import os\n",
    "\n",
    "checkpoint_dir = Path(OUTPUT_DIR)\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = sorted(checkpoint_dir.glob(\"checkpoint-*\"))\n",
    "    \n",
    "    if checkpoints:\n",
    "        print(f\"ğŸ“¦ æ‰¾åˆ° {len(checkpoints)} ä¸ª checkpoint:\\n\")\n",
    "        for cp in checkpoints:\n",
    "            step = cp.name.split(\"-\")[-1]\n",
    "            size_mb = sum(f.stat().st_size for f in cp.rglob('*')) / (1024 * 1024)\n",
    "            print(f\"  - {cp.name} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"âœ… æœ€æ–° checkpoint: {checkpoints[-1].name}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ è¿˜æ²¡æœ‰æ‰¾åˆ° checkpoint\")\n",
    "        print(\"è®­ç»ƒå¯èƒ½åˆšå¼€å§‹æˆ–è¿˜æœªå¼€å§‹\")\n",
    "else:\n",
    "    print(\"âš ï¸ è¾“å‡ºç›®å½•ä¸å­˜åœ¨\")\n",
    "    print(f\"è¯·ç¡®è®¤è®­ç»ƒå·²å¼€å§‹ï¼Œè¾“å‡ºç›®å½•: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š æ­¥éª¤ 9: æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹æœ€æ–°çš„è®­ç»ƒæ—¥å¿—\n",
    "log_dir = Path(OUTPUT_DIR)\n",
    "if log_dir.exists():\n",
    "    log_files = list(log_dir.glob(\"*.log\"))\n",
    "    \n",
    "    if log_files:\n",
    "        latest_log = sorted(log_files, key=lambda x: x.stat().st_mtime)[-1]\n",
    "        print(f\"ğŸ“„ æœ€æ–°æ—¥å¿—æ–‡ä»¶: {latest_log}\")\n",
    "        print()\n",
    "        print(\"æœ€å 50 è¡Œï¼š\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        with open(latest_log, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[-50:]:\n",
    "                print(line.rstrip())\n",
    "    else:\n",
    "        print(\"âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶\")\n",
    "else:\n",
    "    print(\"âš ï¸ è¾“å‡ºç›®å½•ä¸å­˜åœ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… è®­ç»ƒå®Œæˆåçš„æ­¥éª¤\n",
    "\n",
    "### 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒå®Œæˆåï¼ŒåŠ è½½æœ€ä½³ checkpoint\n",
    "\n",
    "checkpoint_dir = Path(OUTPUT_DIR)\n",
    "checkpoints = sorted(checkpoint_dir.glob(\"checkpoint-*\"))\n",
    "\n",
    "if checkpoints:\n",
    "    model_path = str(checkpoints[-1])  # ä½¿ç”¨æœ€æ–°çš„ checkpoint\n",
    "    print(f\"ğŸ“¦ åŠ è½½ checkpoint: {model_path}\")\n",
    "    \n",
    "    trained_policy = SmolVLAPolicy.from_pretrained(model_path)\n",
    "    trained_policy = trained_policy.to(device)\n",
    "    trained_policy.eval()\n",
    "    \n",
    "    print(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\n",
    "    print(f\"  è®¾å¤‡: {device}\")\n",
    "    print(f\"  å‚æ•°é‡: {sum(p.numel() for p in trained_policy.parameters()) / 1e6:.1f}M\")\n",
    "else:\n",
    "    print(\"âš ï¸ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹\")\n",
    "    print(\"è¯·å…ˆå®Œæˆè®­ç»ƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ä¸‹ä¸€æ­¥\n",
    "\n",
    "è®­ç»ƒå®Œæˆåï¼Œæ‚¨å¯ä»¥ï¼š\n",
    "\n",
    "1. **è¯„ä¼°æ¨¡å‹**:\n",
    "   - æ‰“å¼€ `03_evaluate_policy.ipynb`\n",
    "   - åœ¨ MuJoCo ç¯å¢ƒä¸­æµ‹è¯•æ¨¡å‹æ€§èƒ½\n",
    "\n",
    "2. **ä¸Šä¼ æ¨¡å‹åˆ° Hub**:\n",
    "   - åˆ†äº«æ‚¨çš„æ¨¡å‹ç»™ç¤¾åŒº\n",
    "   - ä¾¿äºåç»­ä½¿ç”¨å’Œéƒ¨ç½²\n",
    "\n",
    "3. **ä¼˜åŒ–å’Œæ”¹è¿›**:\n",
    "   - æ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´è¶…å‚æ•°\n",
    "   - é‡‡é›†æ›´å¤šé«˜è´¨é‡æ•°æ®\n",
    "   - å°è¯•ä¸åŒçš„è®­ç»ƒç­–ç•¥\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ è®­ç»ƒå®Œæˆï¼ç»§ç»­ä¸‹ä¸€æ­¥è¯„ä¼°å§ï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
